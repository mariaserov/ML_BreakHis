{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2b941b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "386bcb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/rds/general/user/ft824/home/ML_BreakHis/scr\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "8c67e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#download pretrained weights \n",
    "#model = ResNet50(weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "98a41946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pretrained weight without last layer\n",
    "resnet_weights_path = '/rds/general/user/ft824/home/.keras/models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "CHANNELS = 3\n",
    "IMAGE_RESIZE = 224\n",
    "NUM_CLASSES = 2 # change this to match your number of output classes\n",
    "DENSE_LAYER_ACTIVATION = 'sigmoid'  # use 'softmax' for categorical classification\n",
    "RESNET50_POOLING_AVERAGE = 'avg'  \n",
    "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
    "\n",
    "# Common accuracy metric for all outputs, but can use different metrics for different output\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
    "NUM_EPOCHS = 10\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "STEPS_PER_EPOCH_TRAINING = 10\n",
    "STEPS_PER_EPOCH_VALIDATION = 10\n",
    "\n",
    "#BATCH_SIZE sould be FACTOR of no of img in train and validation\n",
    "BATCH_SIZE_TRAINING = 32\n",
    "BATCH_SIZE_VALIDATION = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "a710f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add pre-trained ResNet50 as the base (without the top classifier layer)\n",
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling=RESNET50_POOLING_AVERAGE,\n",
    "    weights=resnet_weights_path,\n",
    "    input_shape=(224, 224, 3)  # or your image size\n",
    "))\n",
    "\n",
    "# Freeze the base model, not to train first layer\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "# Add output layer for classification\n",
    "model.add(Dense(NUM_CLASSES, activation=DENSE_LAYER_ACTIVATION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "650bd1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m4,098\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,591,810</span> (90.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,591,810\u001b[0m (90.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> (16.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,098\u001b[0m (16.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "60bf03d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/ft824/home/anaconda3/envs/breakhis/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Define optimizer\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=sgd, loss=OBJECTIVE_FUNCTION, metrics=LOSS_METRICS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "688dc8a1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 4458 validated image filenames belonging to 2 classes.\n",
      "Found 1483 validated image filenames belonging to 2 classes.\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Load your CSV files\n",
    "train_df = pd.read_csv('../data/augmented_train_dataset.csv')\n",
    "#augment_train = pd.read_csv('../data/augmented_dataset.csv')\n",
    "#train_df = pd.concat([train_df, augment_train], axis=0, ignore_index=True)\n",
    "\n",
    "test_df = pd.read_csv('../data/new_test.csv')\n",
    "\n",
    "image_size = IMAGE_RESIZE  # for ResNet50\n",
    "\n",
    "\n",
    "# Define the ImageDataGenerator with preprocessing\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "# Training generator\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filepath',    # column with image file paths\n",
    "    y_col='label',       # column with image labels\n",
    "    target_size=(image_size, image_size),  # resizing to match ResNet50 input size\n",
    "    batch_size=BATCH_SIZE_TRAINING,\n",
    "    class_mode='categorical' # multi-class classification\n",
    ")\n",
    "\n",
    "# Test generator\n",
    "test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filepath',    # column with image file paths\n",
    "    y_col='label',       # column with image labels\n",
    "    target_size=(image_size, image_size),  # resizing to match ResNet50 input size\n",
    "    batch_size=BATCH_SIZE_VALIDATION,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "c4c9310b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 140, 16, 93)"
      ]
     },
     "execution_count": 21,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(BATCH_SIZE_TRAINING, len(train_generator), BATCH_SIZE_VALIDATION, len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5438a360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ../../.cache/kagglehub/datasets/ambarish/break...\n",
      "1    ../../.cache/kagglehub/datasets/ambarish/break...\n",
      "2    ../../.cache/kagglehub/datasets/ambarish/break...\n",
      "3    ../../.cache/kagglehub/datasets/ambarish/break...\n",
      "4    ../../.cache/kagglehub/datasets/ambarish/break...\n",
      "Name: filepath, dtype: object\n",
      "Missing files: 0\n",
      "Empty DataFrame\n",
      "Columns: [filepath, label, magnification, tumor_subtype, Unnamed: 0]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "##check for missign files\n",
    "print(train_df['filepath'].head())\n",
    "missing = train_df[~train_df['filepath'].apply(os.path.exists)]\n",
    "print(f\"Missing files: {len(missing)}\")\n",
    "print(missing.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "b4b17c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping & checkpointing the best model in ../working dir & restoring that as our model for prediction\n",
    "from tensorflow.python.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n",
    "cb_checkpointer = ModelCheckpoint(filepath = '../working/best.hdf5', monitor = 'val_loss', save_best_only = True, mode = 'auto')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "32ba4fac",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.model_selection import ParameterGrid\n",
    "\n",
    "# Define grid\n",
    "param_grid = {'epochs': [5, 10, 15], 'steps_per_epoch': [10, 20, 50]}\n",
    "\n",
    "# Create all parameter combinations\n",
    "grid = ParameterGrid(param_grid)\n",
    "\n",
    "# Placeholder for best model tracking\n",
    "best_model = None\n",
    "lowest_val_loss = float('inf')\n",
    "history_list = []\n",
    "\n",
    "# Loop through all parameter combinations\n",
    "for params in grid:\n",
    "    print(f\"Running with params: {params}\")\n",
    "    \n",
    "    # Train your model here using params['epochs'], params['steps_per_epoch'], etc.\n",
    "    # Example:\n",
    "    # model = build_model()\n",
    "    # history = model.fit(..., epochs=params['epochs'], steps_per_epoch=params['steps_per_epoch'], ...)\n",
    "    \n",
    "    # Placeholder for validation loss from this training\n",
    "    val_loss = ...  # replace with actual value from history.history['val_loss'][-1]\n",
    "\n",
    "    # Save history\n",
    "    history_list.append({'params': params, 'val_loss': val_loss})\n",
    "    \n",
    "    # Track best model\n",
    "    if val_loss < lowest_val_loss:\n",
    "        lowest_val_loss = val_loss\n",
    "        best_model = ...  # store model or weights\n",
    "\n",
    "# Analyze history_list to understand trends\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "b7ecd6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/ft824/home/anaconda3/envs/breakhis/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 17s/step - accuracy: 0.5872 - loss: 2.4717 "
     ]
    },
    {
     "ename": "ValueError",
     "evalue": "The following argument(s) are not supported: ['options']",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[25], line 1\u001b[0m\n\u001b[0;32m----> 1\u001b[0m fit_history \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mfit\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m      2\u001b[0m \u001b[43m        \u001b[49m\u001b[43mtrain_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      3\u001b[0m \u001b[43m        \u001b[49m\u001b[43msteps_per_epoch\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEPS_PER_EPOCH_TRAINING\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[43m        \u001b[49m\u001b[43mepochs\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m \u001b[49m\u001b[43mNUM_EPOCHS\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      5\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_data\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtest_generator\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      6\u001b[0m \u001b[43m        \u001b[49m\u001b[43mvalidation_steps\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mSTEPS_PER_EPOCH_VALIDATION\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m      7\u001b[0m \u001b[43m        \u001b[49m\u001b[43mcallbacks\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m[\u001b[49m\u001b[43mcb_checkpointer\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mcb_early_stopper\u001b[49m\u001b[43m]\u001b[49m\n\u001b[1;32m      8\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m      9\u001b[0m model\u001b[38;5;241m.\u001b[39mload_weights(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m/working/best.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/breakhis/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/breakhis/lib/python3.10/site-packages/keras/src/saving/saving_api.py:76\u001b[0m, in \u001b[0;36msave_model\u001b[0;34m(model, filepath, overwrite, zipped, **kwargs)\u001b[0m\n\u001b[1;32m     69\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     70\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe `save_format` argument is deprecated in Keras 3. \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     71\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mPlease remove this argument and pass a file path with \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     72\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124meither `.keras` or `.h5` extension.\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     73\u001b[0m             \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mReceived: save_format=\u001b[39m\u001b[38;5;132;01m{\u001b[39;00msave_format\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     74\u001b[0m         )\n\u001b[1;32m     75\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m kwargs:\n\u001b[0;32m---> 76\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mValueError\u001b[39;00m(\n\u001b[1;32m     77\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mThe following argument(s) are not supported: \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     78\u001b[0m         \u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{\u001b[39;00m\u001b[38;5;28mlist\u001b[39m(kwargs\u001b[38;5;241m.\u001b[39mkeys())\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m     79\u001b[0m     )\n\u001b[1;32m     81\u001b[0m \u001b[38;5;66;03m# Deprecation warnings\u001b[39;00m\n\u001b[1;32m     82\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;28mstr\u001b[39m(filepath)\u001b[38;5;241m.\u001b[39mendswith((\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.h5\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m.hdf5\u001b[39m\u001b[38;5;124m\"\u001b[39m)):\n",
      "\u001b[0;31mValueError\u001b[0m: The following argument(s) are not supported: ['options']"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "        callbacks=[cb_checkpointer, cb_early_stopper]\n",
    ")\n",
    "model.load_weights(\"/working/best.hdf5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6afee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy function\n",
    "def check_accuracy(output,labels):\n",
    "    _,predpos=output.max(1)\n",
    "    num_samples=len(labels)\n",
    "    num_correct=(predpos==labels).sum()\n",
    "    return (num_correct/num_samples)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbb8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state,filename='clahe.pth.tar'):\n",
    "    print('Saving weights-->')\n",
    "    torch.save(state,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5476fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filename):\n",
    "    print('Loading weights-->')\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optim.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42f092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "num_workers=2\n",
    "learning_rate=0.001\n",
    "print(device)\n",
    "num_epochs=25\n",
    "load_model=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c3dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create resnet model, with respecitve transform\n",
    "model = models.resnet50(pretrained=False)\n",
    "model.fc=nn.Sequential(nn.Linear(2048,1024),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Linear(1024,512),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Linear(512,2))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optim=torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load('weights.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add04b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load data\n",
    "#train, validation, test\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size,num_workers=num_workers, shuffle=True)\n",
    "validation_loader = DataLoader(valid_set, batch_size=batch_size,num_workers=num_workers,shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size,num_workers=num_workers,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f305bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Put model on cuda \n",
    "model.to(device)\n",
    "# Put the model on train mode\n",
    "model.train()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14216ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i,y=next(iter(train_loader))\n",
    "i=i.to(device)\n",
    "y=y.to(device)\n",
    "y_pred=model(i)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f506c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for the model\n",
    "min_loss=None\n",
    "for epoch in range(num_epochs):\n",
    "    losses=[]\n",
    "    accuracies=[]\n",
    "    loop= tqdm(enumerate(train_loader),total=len(train_loader),leave=False)\n",
    "    for batch_idx, (data,labels) in loop:\n",
    "        # Put data on cuda\n",
    "        data=data.to(device)\n",
    "        labels=labels.to(device).long()\n",
    "        \n",
    "        # Forward pass\n",
    "        output=model(data)\n",
    "        \n",
    "        # Find out loss\n",
    "        loss=criterion(output,labels)\n",
    "        accuracy=check_accuracy(output,labels)\n",
    "        losses.append(loss.detach().item())\n",
    "        accuracies.append(accuracy.detach().item())\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "        \n",
    "        # Step\n",
    "        optim.step()\n",
    "        \n",
    "        # Update TQDM progress bar\n",
    "        loop.set_description(f\"Epoch [{epoch}/{num_epochs}] \")\n",
    "        loop.set_postfix(loss=loss.detach().item(),accuracy=accuracy.detach().item())\n",
    "        \n",
    "    moving_loss=sum(losses)/len(losses)\n",
    "    moving_accuracy=sum(accuracies)/len(accuracies)\n",
    "    checkpoint={'state_dict': model.state_dict(),'optimizer': optim.state_dict()}\n",
    "    # Save check point\n",
    "    if min_loss==None:\n",
    "        min_loss=moving_loss\n",
    "        save_checkpoint(checkpoint)\n",
    "    elif moving_loss<min_loss:\n",
    "        min_loss=moving_loss\n",
    "        save_checkpoint(checkpoint)\n",
    "    print('Epoch {0} : Loss = {1} , Accuracy={2}'.format(epoch,moving_loss,moving_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation accuracy\n",
    "correct=0\n",
    "samples=0\n",
    "for data,labels in validation_loader:\n",
    "    data=data.to(device)\n",
    "    labels=labels.to(device)\n",
    "    # Forward pass\n",
    "    y_pred=model(data)\n",
    "    # Accuracy over entire dataset\n",
    "    _,predpos=y_pred.max(1)\n",
    "    samples+=len(labels)\n",
    "    correct+=(predpos==labels).sum().detach().item()\n",
    "print('Validation accuracy : ',(correct/samples)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test accuracy\n",
    "correct=0\n",
    "samples=0\n",
    "for data,labels in test_loader:\n",
    "    data=data.to(device)\n",
    "    labels=labels.to(device)\n",
    "    # Forward pass\n",
    "    y_pred=model(data)\n",
    "    # Accuracy over entire dataset\n",
    "    _,predpos=y_pred.max(1)\n",
    "    samples+=len(labels)\n",
    "    correct+=(predpos==labels).sum().detach().item()\n",
    "print('Test accuracy : ',(correct/samples)*100)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "breakhis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
