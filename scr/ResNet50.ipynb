{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "2b941b41",
   "metadata": {},
   "outputs": [],
   "source": [
    "import os\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "import torchvision.transforms as transforms\n",
    "import torchvision\n",
    "from torchvision import models\n",
    "from torch.utils.data import Dataset, DataLoader, random_split\n",
    "from PIL import Image\n",
    "from tqdm import tqdm\n",
    "import shutil\n",
    "import glob\n",
    "import cv2 as cv\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "id": "386bcb49",
   "metadata": {},
   "outputs": [],
   "source": [
    "os.chdir(\"/rds/general/user/ft824/home/ML_BreakHis/data\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "id": "8c67e73b",
   "metadata": {},
   "outputs": [],
   "source": [
    "from tensorflow.keras.applications import ResNet50\n",
    "from tensorflow.keras.models import Sequential\n",
    "from tensorflow.keras.layers import Dense\n",
    "\n",
    "#download pretrained weights \n",
    "#model = ResNet50(weights='imagenet', include_top=False)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "id": "98a41946",
   "metadata": {},
   "outputs": [],
   "source": [
    "# get pretrained weight without last layer\n",
    "resnet_weights_path = '/rds/general/user/ft824/home/.keras/models/resnet50_weights_tf_dim_ordering_tf_kernels_notop.h5'\n",
    "\n",
    "CHANNELS = 3\n",
    "IMAGE_RESIZE = 224\n",
    "NUM_CLASSES = 2 # change this to match your number of output classes\n",
    "DENSE_LAYER_ACTIVATION = 'sigmoid'  # use 'softmax' for categorical classification\n",
    "RESNET50_POOLING_AVERAGE = 'avg'  \n",
    "OBJECTIVE_FUNCTION = 'categorical_crossentropy'\n",
    "\n",
    "# Common accuracy metric for all outputs, but can use different metrics for different output\n",
    "LOSS_METRICS = ['accuracy']\n",
    "\n",
    "# EARLY_STOP_PATIENCE must be < NUM_EPOCHS\n",
    "NUM_EPOCHS = 10\n",
    "EARLY_STOP_PATIENCE = 3\n",
    "\n",
    "# These steps value should be proper FACTOR of no.-of-images in train & valid folders respectively\n",
    "STEPS_PER_EPOCH_TRAINING = 10\n",
    "STEPS_PER_EPOCH_VALIDATION = 10\n",
    "\n",
    "#BATCH_SIZE sould be FACTOR of no of img in train and validation\n",
    "BATCH_SIZE_TRAINING = 32\n",
    "BATCH_SIZE_VALIDATION = 16"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "a710f740",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Build the model\n",
    "model = Sequential()\n",
    "\n",
    "# Add pre-trained ResNet50 as the base (without the top classifier layer)\n",
    "model.add(ResNet50(\n",
    "    include_top=False,\n",
    "    pooling=RESNET50_POOLING_AVERAGE,\n",
    "    weights=resnet_weights_path,\n",
    "    input_shape=(224, 224, 3)  # or your image size\n",
    "))\n",
    "\n",
    "# Freeze the base model, not to train first layer\n",
    "model.layers[0].trainable = False\n",
    "\n",
    "# Add output layer for classification\n",
    "model.add(Dense(NUM_CLASSES, activation=DENSE_LAYER_ACTIVATION))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "650bd1bf",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential_1\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential_1\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)           │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2048</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │         <span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ resnet50 (\u001b[38;5;33mFunctional\u001b[0m)           │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2048\u001b[0m)           │    \u001b[38;5;34m23,587,712\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │         \u001b[38;5;34m4,098\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,591,810</span> (90.00 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m23,591,810\u001b[0m (90.00 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">4,098</span> (16.01 KB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m4,098\u001b[0m (16.01 KB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">23,587,712</span> (89.98 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m23,587,712\u001b[0m (89.98 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "60bf03d2",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/ft824/home/anaconda3/envs/breakhis/lib/python3.10/site-packages/keras/src/optimizers/base_optimizer.py:86: UserWarning: Argument `decay` is no longer supported and will be ignored.\n",
      "  warnings.warn(\n"
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.optimizers import SGD\n",
    "\n",
    "# Define optimizer\n",
    "sgd = SGD(learning_rate=0.01, decay=1e-6, momentum=0.9, nesterov=True)\n",
    "\n",
    "# Compile model\n",
    "model.compile(optimizer=sgd, loss=OBJECTIVE_FUNCTION, metrics=LOSS_METRICS)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 18,
   "id": "688dc8a1",
   "metadata": {},
   "outputs": [
    {
     "ename": "TypeError",
     "evalue": "If class_mode=\"categorical\", y_col=\"label\" column values must be type string, list or tuple.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mTypeError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[18], line 19\u001b[0m\n\u001b[1;32m     15\u001b[0m datagen \u001b[38;5;241m=\u001b[39m ImageDataGenerator(preprocessing_function\u001b[38;5;241m=\u001b[39mpreprocess_input)\n\u001b[1;32m     18\u001b[0m \u001b[38;5;66;03m# Training generator\u001b[39;00m\n\u001b[0;32m---> 19\u001b[0m train_generator \u001b[38;5;241m=\u001b[39m \u001b[43mdatagen\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mflow_from_dataframe\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m     20\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtrain_df\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m     21\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mfilepath\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m    \u001b[49m\u001b[38;5;66;43;03m# column with image file paths\u001b[39;49;00m\n\u001b[1;32m     22\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mlabel\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m,\u001b[49m\u001b[43m       \u001b[49m\u001b[38;5;66;43;03m# column with image labels\u001b[39;49;00m\n\u001b[1;32m     23\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mimage_size\u001b[49m\u001b[43m)\u001b[49m\u001b[43m,\u001b[49m\u001b[43m  \u001b[49m\u001b[38;5;66;43;03m# resizing to match ResNet50 input size\u001b[39;49;00m\n\u001b[1;32m     24\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;241;43m32\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m     25\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[38;5;124;43mcategorical\u001b[39;49m\u001b[38;5;124;43m'\u001b[39;49m\u001b[43m \u001b[49m\u001b[38;5;66;43;03m# multi-class classification\u001b[39;49;00m\n\u001b[1;32m     26\u001b[0m \u001b[43m)\u001b[49m\n\u001b[1;32m     28\u001b[0m \u001b[38;5;66;03m# Test generator\u001b[39;00m\n\u001b[1;32m     29\u001b[0m test_generator \u001b[38;5;241m=\u001b[39m datagen\u001b[38;5;241m.\u001b[39mflow_from_dataframe(\n\u001b[1;32m     30\u001b[0m     dataframe\u001b[38;5;241m=\u001b[39mtest_df,\n\u001b[1;32m     31\u001b[0m     x_col\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mfilepath\u001b[39m\u001b[38;5;124m'\u001b[39m,    \u001b[38;5;66;03m# column with image file paths\u001b[39;00m\n\u001b[0;32m   (...)\u001b[0m\n\u001b[1;32m     35\u001b[0m     class_mode\u001b[38;5;241m=\u001b[39m\u001b[38;5;124m'\u001b[39m\u001b[38;5;124mcategorical\u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m     36\u001b[0m )\n",
      "File \u001b[0;32m~/anaconda3/envs/breakhis/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:1208\u001b[0m, in \u001b[0;36mImageDataGenerator.flow_from_dataframe\u001b[0;34m(self, dataframe, directory, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, save_to_dir, save_prefix, save_format, subset, interpolation, validate_filenames, **kwargs)\u001b[0m\n\u001b[1;32m   1201\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_duplicates\u001b[39m\u001b[38;5;124m\"\u001b[39m \u001b[38;5;129;01min\u001b[39;00m kwargs:\n\u001b[1;32m   1202\u001b[0m     warnings\u001b[38;5;241m.\u001b[39mwarn(\n\u001b[1;32m   1203\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdrop_duplicates is deprecated, you can drop duplicates \u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m   1204\u001b[0m         \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mby using the pandas.DataFrame.drop_duplicates method.\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m   1205\u001b[0m         \u001b[38;5;167;01mDeprecationWarning\u001b[39;00m,\n\u001b[1;32m   1206\u001b[0m     )\n\u001b[0;32m-> 1208\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mDataFrameIterator\u001b[49m\u001b[43m(\u001b[49m\n\u001b[1;32m   1209\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdataframe\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1210\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdirectory\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1211\u001b[0m \u001b[43m    \u001b[49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1212\u001b[0m \u001b[43m    \u001b[49m\u001b[43mx_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mx_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1213\u001b[0m \u001b[43m    \u001b[49m\u001b[43my_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43my_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1214\u001b[0m \u001b[43m    \u001b[49m\u001b[43mweight_col\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mweight_col\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1215\u001b[0m \u001b[43m    \u001b[49m\u001b[43mtarget_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mtarget_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1216\u001b[0m \u001b[43m    \u001b[49m\u001b[43mcolor_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mcolor_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1217\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclasses\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclasses\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1218\u001b[0m \u001b[43m    \u001b[49m\u001b[43mclass_mode\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mclass_mode\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1219\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdata_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdata_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1220\u001b[0m \u001b[43m    \u001b[49m\u001b[43mbatch_size\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mbatch_size\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1221\u001b[0m \u001b[43m    \u001b[49m\u001b[43mshuffle\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mshuffle\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1222\u001b[0m \u001b[43m    \u001b[49m\u001b[43mseed\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mseed\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1223\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_to_dir\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_to_dir\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1224\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_prefix\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_prefix\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1225\u001b[0m \u001b[43m    \u001b[49m\u001b[43msave_format\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msave_format\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1226\u001b[0m \u001b[43m    \u001b[49m\u001b[43msubset\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43msubset\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1227\u001b[0m \u001b[43m    \u001b[49m\u001b[43minterpolation\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43minterpolation\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1228\u001b[0m \u001b[43m    \u001b[49m\u001b[43mvalidate_filenames\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[43mvalidate_filenames\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1229\u001b[0m \u001b[43m    \u001b[49m\u001b[43mdtype\u001b[49m\u001b[38;5;241;43m=\u001b[39;49m\u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mdtype\u001b[49m\u001b[43m,\u001b[49m\n\u001b[1;32m   1230\u001b[0m \u001b[43m\u001b[49m\u001b[43m)\u001b[49m\n",
      "File \u001b[0;32m~/anaconda3/envs/breakhis/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:751\u001b[0m, in \u001b[0;36mDataFrameIterator.__init__\u001b[0;34m(self, dataframe, directory, image_data_generator, x_col, y_col, weight_col, target_size, color_mode, classes, class_mode, batch_size, shuffle, seed, data_format, save_to_dir, save_prefix, save_format, subset, interpolation, keep_aspect_ratio, dtype, validate_filenames)\u001b[0m\n\u001b[1;32m    749\u001b[0m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mdtype \u001b[38;5;241m=\u001b[39m dtype\n\u001b[1;32m    750\u001b[0m \u001b[38;5;66;03m# check that inputs match the required class_mode\u001b[39;00m\n\u001b[0;32m--> 751\u001b[0m \u001b[38;5;28;43mself\u001b[39;49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43m_check_params\u001b[49m\u001b[43m(\u001b[49m\u001b[43mdf\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mx_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43my_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mweight_col\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[43mclasses\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m    752\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m (\n\u001b[1;32m    753\u001b[0m     validate_filenames\n\u001b[1;32m    754\u001b[0m ):  \u001b[38;5;66;03m# check which image files are valid and keep them\u001b[39;00m\n\u001b[1;32m    755\u001b[0m     df \u001b[38;5;241m=\u001b[39m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39m_filter_valid_filepaths(df, x_col)\n",
      "File \u001b[0;32m~/anaconda3/envs/breakhis/lib/python3.10/site-packages/keras/src/legacy/preprocessing/image.py:841\u001b[0m, in \u001b[0;36mDataFrameIterator._check_params\u001b[0;34m(self, df, x_col, y_col, weight_col, classes)\u001b[0m\n\u001b[1;32m    839\u001b[0m     types \u001b[38;5;241m=\u001b[39m (\u001b[38;5;28mstr\u001b[39m, \u001b[38;5;28mlist\u001b[39m, \u001b[38;5;28mtuple\u001b[39m)\n\u001b[1;32m    840\u001b[0m     \u001b[38;5;28;01mif\u001b[39;00m \u001b[38;5;129;01mnot\u001b[39;00m \u001b[38;5;28mall\u001b[39m(df[y_col]\u001b[38;5;241m.\u001b[39mapply(\u001b[38;5;28;01mlambda\u001b[39;00m x: \u001b[38;5;28misinstance\u001b[39m(x, types))):\n\u001b[0;32m--> 841\u001b[0m         \u001b[38;5;28;01mraise\u001b[39;00m \u001b[38;5;167;01mTypeError\u001b[39;00m(\n\u001b[1;32m    842\u001b[0m             \u001b[38;5;124m'\u001b[39m\u001b[38;5;124mIf class_mode=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m, y_col=\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;132;01m{}\u001b[39;00m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124m column \u001b[39m\u001b[38;5;124m'\u001b[39m\n\u001b[1;32m    843\u001b[0m             \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mvalues must be type string, list or tuple.\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;241m.\u001b[39mformat(\n\u001b[1;32m    844\u001b[0m                 \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_mode, y_col\n\u001b[1;32m    845\u001b[0m             )\n\u001b[1;32m    846\u001b[0m         )\n\u001b[1;32m    847\u001b[0m \u001b[38;5;66;03m# raise warning if classes are given but will be unused\u001b[39;00m\n\u001b[1;32m    848\u001b[0m \u001b[38;5;28;01mif\u001b[39;00m classes \u001b[38;5;129;01mand\u001b[39;00m \u001b[38;5;28mself\u001b[39m\u001b[38;5;241m.\u001b[39mclass_mode \u001b[38;5;129;01min\u001b[39;00m {\n\u001b[1;32m    849\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124minput\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    850\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mmulti_output\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    851\u001b[0m     \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mraw\u001b[39m\u001b[38;5;124m\"\u001b[39m,\n\u001b[1;32m    852\u001b[0m     \u001b[38;5;28;01mNone\u001b[39;00m,\n\u001b[1;32m    853\u001b[0m }:\n",
      "\u001b[0;31mTypeError\u001b[0m: If class_mode=\"categorical\", y_col=\"label\" column values must be type string, list or tuple."
     ]
    }
   ],
   "source": [
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "\n",
    "# Load your CSV files\n",
    "train_df = pd.read_csv('../data/augmented_train_dataset.csv')\n",
    "#augment_train = pd.read_csv('../data/augmented_dataset.csv')\n",
    "#train_df = pd.concat([train_df, augment_train], axis=0, ignore_index=True)\n",
    "\n",
    "test_df = pd.read_csv('../data/new_test.csv')\n",
    "\n",
    "image_size = 224  # for ResNet50\n",
    "\n",
    "\n",
    "# Define the ImageDataGenerator with preprocessing\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "\n",
    "# Training generator\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filepath',    # column with image file paths\n",
    "    y_col='label',       # column with image labels\n",
    "    target_size=(image_size, image_size),  # resizing to match ResNet50 input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical' # multi-class classification\n",
    ")\n",
    "\n",
    "# Test generator\n",
    "test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filepath',    # column with image file paths\n",
    "    y_col='label',       # column with image labels\n",
    "    target_size=(image_size, image_size),  # resizing to match ResNet50 input size\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 23,
   "id": "c4c9310b",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(32, 182, 16, 93)"
      ]
     },
     "execution_count": 23,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "(BATCH_SIZE_TRAINING, len(train_generator), BATCH_SIZE_VALIDATION, len(test_generator))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "5438a360",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0    ../train_aug/original_2621.png\n",
      "1    ../train_aug/original_4985.png\n",
      "2    ../train_aug/original_3990.png\n",
      "3    ../train_aug/original_2934.png\n",
      "4    ../train_aug/original_4068.png\n",
      "Name: filepath, dtype: object\n",
      "Missing files: 0\n",
      "Empty DataFrame\n",
      "Columns: [filepath, label, magnification, tumor_subtype]\n",
      "Index: []\n"
     ]
    }
   ],
   "source": [
    "##check for missing files\n",
    "print(train_df['filepath'].head())\n",
    "missing = train_df[~train_df['filepath'].apply(os.path.exists)]\n",
    "print(f\"Missing files: {len(missing)}\")\n",
    "print(missing.head())\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "b4b17c4d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Early stopping & checkpointing the best model in ../working dir & restoring that as our model for prediction\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "\n",
    "cb_early_stopper = EarlyStopping(monitor = 'val_loss', patience = EARLY_STOP_PATIENCE)\n",
    "cb_checkpointer = ModelCheckpoint(filepath = '../working/best.weights.h5', monitor = 'val_loss', save_best_only = True, save_weights_only=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 34,
   "id": "b7ecd6b6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch 1/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m256s\u001b[0m 27s/step - accuracy: 0.8028 - loss: 0.7943 - val_accuracy: 0.7937 - val_loss: 0.7476\n",
      "Epoch 2/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m323s\u001b[0m 34s/step - accuracy: 0.8280 - loss: 0.5253 - val_accuracy: 0.8750 - val_loss: 0.4148\n",
      "Epoch 3/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m341s\u001b[0m 35s/step - accuracy: 0.8854 - loss: 0.4089 - val_accuracy: 0.7812 - val_loss: 0.7345\n",
      "Epoch 4/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m334s\u001b[0m 35s/step - accuracy: 0.8247 - loss: 0.6729 - val_accuracy: 0.8438 - val_loss: 0.6105\n",
      "Epoch 5/10\n",
      "\u001b[1m10/10\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m314s\u001b[0m 33s/step - accuracy: 0.9043 - loss: 0.3639 - val_accuracy: 0.8562 - val_loss: 0.6322\n"
     ]
    }
   ],
   "source": [
    "fit_history = model.fit(\n",
    "        train_generator,\n",
    "        steps_per_epoch=STEPS_PER_EPOCH_TRAINING,\n",
    "        epochs = NUM_EPOCHS,\n",
    "        validation_data=test_generator,\n",
    "        validation_steps=STEPS_PER_EPOCH_VALIDATION,\n",
    "        callbacks=[cb_checkpointer, cb_early_stopper]\n",
    ")\n",
    "model.load_weights(\"../working/best.weights.h5\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "b70f33a1",
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 30,
   "id": "fe633df6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "2.18.0\n"
     ]
    }
   ],
   "source": [
    "print(tf.__version__)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "f6afee56",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Check accuracy function\n",
    "def check_accuracy(output,labels):\n",
    "    _,predpos=output.max(1)\n",
    "    num_samples=len(labels)\n",
    "    num_correct=(predpos==labels).sum()\n",
    "    return (num_correct/num_samples)*100\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "38fbb8b1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def save_checkpoint(state,filename='clahe.pth.tar'):\n",
    "    print('Saving weights-->')\n",
    "    torch.save(state,filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "5476fad1",
   "metadata": {},
   "outputs": [],
   "source": [
    "def load_checkpoint(filename):\n",
    "    print('Loading weights-->')\n",
    "    model.load_state_dict(checkpoint['state_dict'])\n",
    "    optim.load_state_dict(checkpoint['optimizer'])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "c42f092c",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Parameters\n",
    "device = torch.device(\"cuda\" if torch.cuda.is_available() else \"cpu\")\n",
    "batch_size = 32\n",
    "shuffle_dataset = True\n",
    "random_seed= 42\n",
    "num_workers=2\n",
    "learning_rate=0.001\n",
    "print(device)\n",
    "num_epochs=25\n",
    "load_model=False"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "2f9c3dc3",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Create resnet model, with respecitve transform\n",
    "model = models.resnet50(pretrained=False)\n",
    "model.fc=nn.Sequential(nn.Linear(2048,1024),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Linear(1024,512),\n",
    "                      nn.LeakyReLU(),\n",
    "                      nn.Linear(512,2))\n",
    "print(model)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "6f35316d",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Loss and Optimizer\n",
    "criterion=nn.CrossEntropyLoss()\n",
    "optim=torch.optim.Adam(model.parameters(),lr=learning_rate)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "4b44495d",
   "metadata": {},
   "outputs": [],
   "source": [
    "if load_model:\n",
    "    load_checkpoint(torch.load('weights.pth.tar'))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "add04b44",
   "metadata": {},
   "outputs": [],
   "source": [
    "##Load data\n",
    "#train, validation, test\n",
    "train_loader = DataLoader(train_set, batch_size=batch_size,num_workers=num_workers, shuffle=True)\n",
    "validation_loader = DataLoader(valid_set, batch_size=batch_size,num_workers=num_workers,shuffle=True)\n",
    "test_loader = DataLoader(test_set, batch_size=batch_size,num_workers=num_workers,shuffle=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "3f305bd7",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Put model on cuda \n",
    "model.to(device)\n",
    "# Put the model on train mode\n",
    "model.train()\n",
    "print()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "14216ae1",
   "metadata": {},
   "outputs": [],
   "source": [
    "i,y=next(iter(train_loader))\n",
    "i=i.to(device)\n",
    "y=y.to(device)\n",
    "y_pred=model(i)\n",
    "print(y_pred.shape)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "f506c40f",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Training loop for the model\n",
    "min_loss=None\n",
    "for epoch in range(num_epochs):\n",
    "    losses=[]\n",
    "    accuracies=[]\n",
    "    loop= tqdm(enumerate(train_loader),total=len(train_loader),leave=False)\n",
    "    for batch_idx, (data,labels) in loop:\n",
    "        # Put data on cuda\n",
    "        data=data.to(device)\n",
    "        labels=labels.to(device).long()\n",
    "        \n",
    "        # Forward pass\n",
    "        output=model(data)\n",
    "        \n",
    "        # Find out loss\n",
    "        loss=criterion(output,labels)\n",
    "        accuracy=check_accuracy(output,labels)\n",
    "        losses.append(loss.detach().item())\n",
    "        accuracies.append(accuracy.detach().item())\n",
    "        \n",
    "        optim.zero_grad()\n",
    "        \n",
    "        # Back prop\n",
    "        loss.backward()\n",
    "        \n",
    "        # Step\n",
    "        optim.step()\n",
    "        \n",
    "        # Update TQDM progress bar\n",
    "        loop.set_description(f\"Epoch [{epoch}/{num_epochs}] \")\n",
    "        loop.set_postfix(loss=loss.detach().item(),accuracy=accuracy.detach().item())\n",
    "        \n",
    "    moving_loss=sum(losses)/len(losses)\n",
    "    moving_accuracy=sum(accuracies)/len(accuracies)\n",
    "    checkpoint={'state_dict': model.state_dict(),'optimizer': optim.state_dict()}\n",
    "    # Save check point\n",
    "    if min_loss==None:\n",
    "        min_loss=moving_loss\n",
    "        save_checkpoint(checkpoint)\n",
    "    elif moving_loss<min_loss:\n",
    "        min_loss=moving_loss\n",
    "        save_checkpoint(checkpoint)\n",
    "    print('Epoch {0} : Loss = {1} , Accuracy={2}'.format(epoch,moving_loss,moving_accuracy))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "af13acd1",
   "metadata": {},
   "outputs": [],
   "source": [
    "# Validation accuracy\n",
    "correct=0\n",
    "samples=0\n",
    "for data,labels in validation_loader:\n",
    "    data=data.to(device)\n",
    "    labels=labels.to(device)\n",
    "    # Forward pass\n",
    "    y_pred=model(data)\n",
    "    # Accuracy over entire dataset\n",
    "    _,predpos=y_pred.max(1)\n",
    "    samples+=len(labels)\n",
    "    correct+=(predpos==labels).sum().detach().item()\n",
    "print('Validation accuracy : ',(correct/samples)*100)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "ee81794b",
   "metadata": {},
   "outputs": [],
   "source": [
    "\n",
    "# Test accuracy\n",
    "correct=0\n",
    "samples=0\n",
    "for data,labels in test_loader:\n",
    "    data=data.to(device)\n",
    "    labels=labels.to(device)\n",
    "    # Forward pass\n",
    "    y_pred=model(data)\n",
    "    # Accuracy over entire dataset\n",
    "    _,predpos=y_pred.max(1)\n",
    "    samples+=len(labels)\n",
    "    correct+=(predpos==labels).sum().detach().item()\n",
    "print('Test accuracy : ',(correct/samples)*100)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "0db4c9c4",
   "metadata": {},
   "source": [
    "Prediction\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "id": "72256bed",
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from tensorflow.keras.applications.resnet50 import preprocess_input\n",
    "from sklearn.metrics import confusion_matrix, ConfusionMatrixDisplay\n",
    "from tensorflow.keras.models import load_model\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "c4070eeb",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5820 validated image filenames belonging to 2 classes.\n",
      "Found 1978 validated image filenames.\n"
     ]
    }
   ],
   "source": [
    "\n",
    "#Define generator for the unseen/test data\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_df = pd.read_csv(\"../data/augmented_train_dataset.csv\")\n",
    "train_df['filepath'] = train_df['filepath'].str.replace(r\"^\\.\\./\", \"../data/\", regex=True)\n",
    "\n",
    "#convert labels to string\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "\n",
    "holdout_data = pd.read_csv(\"../data/new_holdout.csv\")\n",
    "\n",
    "image_size = 224  # for ResNet50\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filepath',    # column with image file paths\n",
    "    y_col='label',       # column with image labels\n",
    "    target_size=(image_size, image_size),  # resizing to match ResNet50 input size\n",
    "    batch_size=32,\n",
    "    class_mode='categorical' # multi-class classification\n",
    ")\n",
    "\n",
    "unseen_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=holdout_data,           \n",
    "    x_col='filepath',\n",
    "    y_col=None,                 #labels for unseen data\n",
    "    target_size=(224, 224),        # <- match input size to model\n",
    "    class_mode=None,               # <- no class_mode\n",
    "    batch_size=32,\n",
    "    shuffle=False                  # <- don't shuffle, to keep predictions in order\n",
    ")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 26,
   "id": "e5655206",
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:Compiled the loaded model, but the compiled metrics have yet to be built. `model.compile_metrics` will be empty until you train or evaluate the model.\n",
      "/rds/general/user/ft824/home/anaconda3/envs/breakhis/lib/python3.10/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m62/62\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m1812s\u001b[0m 29s/step\n",
      "{'0': 0, '1': 1}\n"
     ]
    }
   ],
   "source": [
    "#load trained resnet model\n",
    "model = load_model(\"resnet50_best_model.h5\")\n",
    "predictions = model.predict(unseen_generator)\n",
    "\n",
    "### get labels\n",
    "predicted_classes = np.argmax(predictions, axis=1)  # for categorical output\n",
    "\n",
    "class_indices = train_generator.class_indices\n",
    "label_map = {0: \"benign\", 1: \"malignant\"}\n",
    "\n",
    "predicted_labels = [label_map[i] for i in predicted_classes]\n",
    "\n",
    "print(train_generator.class_indices)\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 27,
   "id": "f369f4af",
   "metadata": {},
   "outputs": [
    {
     "ename": "ValueError",
     "evalue": "None values not supported.",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mValueError\u001b[0m                                Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[27], line 3\u001b[0m\n\u001b[1;32m      1\u001b[0m \u001b[38;5;66;03m##evaluate accuracy\u001b[39;00m\n\u001b[0;32m----> 3\u001b[0m loss, accuracy \u001b[38;5;241m=\u001b[39m \u001b[43mmodel\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43mevaluate\u001b[49m\u001b[43m(\u001b[49m\u001b[43munseen_generator\u001b[49m\u001b[43m)\u001b[49m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;28;01mwith\u001b[39;00m \u001b[38;5;28mopen\u001b[39m(\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mevaluation.txt\u001b[39m\u001b[38;5;124m\"\u001b[39m, \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mw\u001b[39m\u001b[38;5;124m\"\u001b[39m) \u001b[38;5;28;01mas\u001b[39;00m f:\n\u001b[1;32m      5\u001b[0m     f\u001b[38;5;241m.\u001b[39mwrite(\u001b[38;5;124mf\u001b[39m\u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mLoss: \u001b[39m\u001b[38;5;132;01m{\u001b[39;00mloss\u001b[38;5;132;01m}\u001b[39;00m\u001b[38;5;130;01m\\n\u001b[39;00m\u001b[38;5;124m\"\u001b[39m)\n",
      "File \u001b[0;32m~/anaconda3/envs/breakhis/lib/python3.10/site-packages/keras/src/utils/traceback_utils.py:122\u001b[0m, in \u001b[0;36mfilter_traceback.<locals>.error_handler\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m    119\u001b[0m     filtered_tb \u001b[38;5;241m=\u001b[39m _process_traceback_frames(e\u001b[38;5;241m.\u001b[39m__traceback__)\n\u001b[1;32m    120\u001b[0m     \u001b[38;5;66;03m# To get the full stack trace, call:\u001b[39;00m\n\u001b[1;32m    121\u001b[0m     \u001b[38;5;66;03m# `keras.config.disable_traceback_filtering()`\u001b[39;00m\n\u001b[0;32m--> 122\u001b[0m     \u001b[38;5;28;01mraise\u001b[39;00m e\u001b[38;5;241m.\u001b[39mwith_traceback(filtered_tb) \u001b[38;5;28;01mfrom\u001b[39;00m\u001b[38;5;250m \u001b[39m\u001b[38;5;28;01mNone\u001b[39;00m\n\u001b[1;32m    123\u001b[0m \u001b[38;5;28;01mfinally\u001b[39;00m:\n\u001b[1;32m    124\u001b[0m     \u001b[38;5;28;01mdel\u001b[39;00m filtered_tb\n",
      "File \u001b[0;32m~/anaconda3/envs/breakhis/lib/python3.10/site-packages/optree/ops.py:766\u001b[0m, in \u001b[0;36mtree_map\u001b[0;34m(func, tree, is_leaf, none_is_leaf, namespace, *rests)\u001b[0m\n\u001b[1;32m    764\u001b[0m leaves, treespec \u001b[38;5;241m=\u001b[39m _C\u001b[38;5;241m.\u001b[39mflatten(tree, is_leaf, none_is_leaf, namespace)\n\u001b[1;32m    765\u001b[0m flat_args \u001b[38;5;241m=\u001b[39m [leaves] \u001b[38;5;241m+\u001b[39m [treespec\u001b[38;5;241m.\u001b[39mflatten_up_to(r) \u001b[38;5;28;01mfor\u001b[39;00m r \u001b[38;5;129;01min\u001b[39;00m rests]\n\u001b[0;32m--> 766\u001b[0m \u001b[38;5;28;01mreturn\u001b[39;00m \u001b[43mtreespec\u001b[49m\u001b[38;5;241;43m.\u001b[39;49m\u001b[43munflatten\u001b[49m\u001b[43m(\u001b[49m\u001b[38;5;28;43mmap\u001b[39;49m\u001b[43m(\u001b[49m\u001b[43mfunc\u001b[49m\u001b[43m,\u001b[49m\u001b[43m \u001b[49m\u001b[38;5;241;43m*\u001b[39;49m\u001b[43mflat_args\u001b[49m\u001b[43m)\u001b[49m\u001b[43m)\u001b[49m\n",
      "\u001b[0;31mValueError\u001b[0m: None values not supported."
     ]
    }
   ],
   "source": [
    "\n",
    "##evaluate accuracy\n",
    "\n",
    "loss, accuracy = model.evaluate(unseen_generator)\n",
    "with open(\"evaluation.txt\", \"w\") as f:\n",
    "    f.write(f\"Loss: {loss}\\n\")\n",
    "    f.write(f\"Accuracy: {accuracy}\\n\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 28,
   "id": "b123f956",
   "metadata": {},
   "outputs": [
    {
     "data": {
      "image/png": "iVBORw0KGgoAAAANSUhEUgAAAj8AAAHHCAYAAABQhTneAAAAOnRFWHRTb2Z0d2FyZQBNYXRwbG90bGliIHZlcnNpb24zLjEwLjEsIGh0dHBzOi8vbWF0cGxvdGxpYi5vcmcvc2/+5QAAAAlwSFlzAAAPYQAAD2EBqD+naQAAU6RJREFUeJzt3XlYVGX7B/DvGZCdGRZlUwRX3MUtw91E0dAw7VWMEvcscdfUn0uomYWmhrmkllv4qpVSUpoI7pI7aoYkblACmsiqrHN+f/AyNcIkwwyLZ76frnNdzjnPec59JsK7+3mecwRRFEUQERERGQhZdQdAREREVJWY/BAREZFBYfJDREREBoXJDxERERkUJj9ERERkUJj8EBERkUFh8kNEREQGhckPERERGRQmP0RERGRQmPwQGbibN2+iX79+UCgUEAQB4eHheu3/7t27EAQB27Zt02u/L7JevXqhV69e1R0GkcFi8kNUA9y6dQvvvPMOGjZsCDMzM8jlcnTt2hWfffYZnj59WqnXDgwMxLVr17Bs2TLs3LkTHTt2rNTrVaVRo0ZBEATI5fIyv8ebN29CEAQIgoCVK1dq3f/9+/cRHByM2NhYPURLRFXFuLoDIDJ0P/74I/7zn//A1NQUI0eORKtWrZCfn49Tp05h9uzZuH79OjZt2lQp13769CliYmIwf/58BAUFVco13Nzc8PTpU9SqVatS+n8eY2NjPHnyBAcOHMCwYcPUjoWFhcHMzAy5ubkV6vv+/ftYvHgx3N3d4enpWe7zDh8+XKHrEZF+MPkhqkZ37tyBv78/3NzcEB0dDWdnZ9WxSZMmISEhAT/++GOlXf/hw4cAABsbm0q7hiAIMDMzq7T+n8fU1BRdu3bFf//731LJz65du+Dr64vvvvuuSmJ58uQJLCwsYGJiUiXXI6KycdiLqBqFhIQgOzsbX375pVriU6Jx48aYOnWq6nNhYSGWLl2KRo0awdTUFO7u7vi///s/5OXlqZ3n7u6OgQMH4tSpU3jppZdgZmaGhg0bYseOHao2wcHBcHNzAwDMnj0bgiDA3d0dQPFwUcmf/yk4OBiCIKjti4yMRLdu3WBjYwMrKyt4eHjg//7v/1THNc35iY6ORvfu3WFpaQkbGxv4+fkhLi6uzOslJCRg1KhRsLGxgUKhwOjRo/HkyRPNX+wz3nzzTRw8eBDp6emqfefPn8fNmzfx5ptvlmqflpaGWbNmoXXr1rCysoJcLseAAQNw5coVVZtjx46hU6dOAIDRo0erhs9K7rNXr15o1aoVLl68iB49esDCwkL1vTw75ycwMBBmZmal7t/Hxwe2tra4f/9+ue+ViJ6PyQ9RNTpw4AAaNmyILl26lKv9uHHjsGjRIrRv3x6rV69Gz549sXz5cvj7+5dqm5CQgDfeeAN9+/bFp59+CltbW4waNQrXr18HAAwZMgSrV68GAIwYMQI7d+7EmjVrtIr/+vXrGDhwIPLy8rBkyRJ8+umneO2113D69Ol/Pe/IkSPw8fHBgwcPEBwcjBkzZuDMmTPo2rUr7t69W6r9sGHDkJWVheXLl2PYsGHYtm0bFi9eXO44hwwZAkEQsG/fPtW+Xbt2oVmzZmjfvn2p9rdv30Z4eDgGDhyIVatWYfbs2bh27Rp69uypSkSaN2+OJUuWAAAmTJiAnTt3YufOnejRo4eqn0ePHmHAgAHw9PTEmjVr0Lt37zLj++yzz1CnTh0EBgaiqKgIAPDFF1/g8OHDWLt2LVxcXMp9r0RUDiIRVYuMjAwRgOjn51eu9rGxsSIAcdy4cWr7Z82aJQIQo6OjVfvc3NxEAOKJEydU+x48eCCampqKM2fOVO27c+eOCEBcsWKFWp+BgYGim5tbqRg++OAD8Z+/NlavXi0CEB8+fKgx7pJrbN26VbXP09NTdHBwEB89eqTad+XKFVEmk4kjR44sdb0xY8ao9fn666+L9vb2Gq/5z/uwtLQURVEU33jjDbFPnz6iKIpiUVGR6OTkJC5evLjM7yA3N1csKioqdR+mpqbikiVLVPvOnz9f6t5K9OzZUwQgbty4scxjPXv2VNv3888/iwDEDz/8ULx9+7ZoZWUlDh48+Ln3SETaY+WHqJpkZmYCAKytrcvV/qeffgIAzJgxQ23/zJkzAaDU3KAWLVqge/fuqs916tSBh4cHbt++XeGYn1UyV+j777+HUqks1znJycmIjY3FqFGjYGdnp9rfpk0b9O3bV3Wf/zRx4kS1z927d8ejR49U32F5vPnmmzh27BhSUlIQHR2NlJSUMoe8gOJ5QjJZ8a/HoqIiPHr0SDWkd+nSpXJf09TUFKNHjy5X2379+uGdd97BkiVLMGTIEJiZmeGLL74o97WIqPyY/BBVE7lcDgDIysoqV/t79+5BJpOhcePGavudnJxgY2ODe/fuqe2vX79+qT5sbW3x+PHjCkZc2vDhw9G1a1eMGzcOjo6O8Pf3x969e/81ESqJ08PDo9Sx5s2b46+//kJOTo7a/mfvxdbWFgC0updXX30V1tbW2LNnD8LCwtCpU6dS32UJpVKJ1atXo0mTJjA1NUXt2rVRp04dXL16FRkZGeW+Zt26dbWa3Lxy5UrY2dkhNjYWoaGhcHBwKPe5RFR+TH6IqolcLoeLiwt+/fVXrc57dsKxJkZGRmXuF0WxwtcomY9SwtzcHCdOnMCRI0fw9ttv4+rVqxg+fDj69u1bqq0udLmXEqamphgyZAi2b9+O/fv3a6z6AMBHH32EGTNmoEePHvj666/x888/IzIyEi1btix3hQso/n60cfnyZTx48AAAcO3aNa3OJaLyY/JDVI0GDhyIW7duISYm5rlt3dzcoFQqcfPmTbX9qampSE9PV63c0gdbW1u1lVElnq0uAYBMJkOfPn2watUq/Pbbb1i2bBmio6Nx9OjRMvsuiTM+Pr7UsRs3bqB27dqwtLTU7QY0ePPNN3H58mVkZWWVOUm8xLfffovevXvjyy+/hL+/P/r16wdvb+9S30l5E9HyyMnJwejRo9GiRQtMmDABISEhOH/+vN76J6K/Mfkhqkbvv/8+LC0tMW7cOKSmppY6fuvWLXz22WcAiodtAJRakbVq1SoAgK+vr97iatSoETIyMnD16lXVvuTkZOzfv1+tXVpaWqlzSx729+zy+xLOzs7w9PTE9u3b1ZKJX3/9FYcPH1bdZ2Xo3bs3li5dis8//xxOTk4a2xkZGZWqKn3zzTf4888/1faVJGllJYramjNnDhITE7F9+3asWrUK7u7uCAwM1Pg9ElHF8SGHRNWoUaNG2LVrF4YPH47mzZurPeH5zJkz+OabbzBq1CgAQNu2bREYGIhNmzYhPT0dPXv2xLlz57B9+3YMHjxY4zLqivD398ecOXPw+uuvY8qUKXjy5Ak2bNiApk2bqk34XbJkCU6cOAFfX1+4ubnhwYMHWL9+PerVq4du3bpp7H/FihUYMGAAvLy8MHbsWDx9+hRr166FQqFAcHCw3u7jWTKZDAsWLHhuu4EDB2LJkiUYPXo0unTpgmvXriEsLAwNGzZUa9eoUSPY2Nhg48aNsLa2hqWlJTp37owGDRpoFVd0dDTWr1+PDz74QLX0fuvWrejVqxcWLlyIkJAQrfojoueo5tVmRCSK4u+//y6OHz9edHd3F01MTERra2uxa9eu4tq1a8Xc3FxVu4KCAnHx4sVigwYNxFq1aomurq7ivHnz1NqIYvFSd19f31LXeXaJtaal7qIoiocPHxZbtWolmpiYiB4eHuLXX39daql7VFSU6OfnJ7q4uIgmJiaii4uLOGLECPH3338vdY1nl4MfOXJE7Nq1q2hubi7K5XJx0KBB4m+//abWpuR6zy6l37p1qwhAvHPnjsbvVBTVl7prommp+8yZM0VnZ2fR3Nxc7Nq1qxgTE1PmEvXvv/9ebNGihWhsbKx2nz179hRbtmxZ5jX/2U9mZqbo5uYmtm/fXiwoKFBrN336dFEmk4kxMTH/eg9EpB1BFLWYMUhERET0guOcHyIiIjIoTH6IiIjIoDD5ISIiIoPC5IeIiIgMCpMfIiIiMihMfoiIiMig8CGHLxClUon79+/D2tpar4/VJyKiqiGKIrKysuDi4gKZrPLqD7m5ucjPz9e5HxMTE5iZmekhopqFyc8L5P79+3B1da3uMIiISEdJSUmoV69epfSdm5sLc2t7oPCJzn05OTnhzp07kkuAmPy8QKytrQEAC785BTMLq2qOhqhyvNW+fnWHQFRpsrIy0aqpu+r3eWXIz88HCp/AtEUgYGRS8Y6K8pHy23bk5+cz+aHqUzLUZWZhBTPLyvsPh6g6yeXy6g6BqNJVydQFYzMIOiQ/oiDdacFMfoiIiKRIAKBLkiXhqaVMfoiIiKRIkBVvupwvUdK9MyIiIqIysPJDREQkRYKg47CXdMe9mPwQERFJEYe9NJLunRERERGVgZUfIiIiKeKwl0ZMfoiIiCRJx2EvCQ8OSffOiIiIiMrAyg8REZEUcdhLIyY/REREUsTVXhpJ986IiIiIysDKDxERkRRx2EsjJj9ERERSxGEvjZj8EBERSRErPxpJN60jIiIiKgMrP0RERFLEYS+NmPwQERFJkSDomPxw2IuIiIhIEpj8EBERSZFM0H3TwokTJzBo0CC4uLhAEASEh4erjhUUFGDOnDlo3bo1LC0t4eLigpEjR+L+/ftqfaSlpSEgIAByuRw2NjYYO3YssrOz1dpcvXoV3bt3h5mZGVxdXRESEqL9V6P1GURERFTzlcz50WXTQk5ODtq2bYt169aVOvbkyRNcunQJCxcuxKVLl7Bv3z7Ex8fjtddeU2sXEBCA69evIzIyEhEREThx4gQmTJigOp6ZmYl+/frBzc0NFy9exIoVKxAcHIxNmzZpFSvn/BAREZHOBgwYgAEDBpR5TKFQIDIyUm3f559/jpdeegmJiYmoX78+4uLicOjQIZw/fx4dO3YEAKxduxavvvoqVq5cCRcXF4SFhSE/Px9fffUVTExM0LJlS8TGxmLVqlVqSdLzsPJDREQkRSXP+dFlQ3G15Z9bXl6eXsLLyMiAIAiwsbEBAMTExMDGxkaV+ACAt7c3ZDIZzp49q2rTo0cPmJiYqNr4+PggPj4ejx8/Lve1mfwQERFJkZ6GvVxdXaFQKFTb8uXLdQ4tNzcXc+bMwYgRIyCXywEAKSkpcHBwUGtnbGwMOzs7pKSkqNo4OjqqtSn5XNKmPDjsRURERBolJSWpEhQAMDU11am/goICDBs2DKIoYsOGDbqGVyFMfoiIiKRIT6+3kMvlasmPLkoSn3v37iE6OlqtXycnJzx48ECtfWFhIdLS0uDk5KRqk5qaqtam5HNJm/LgsBcREZEUVfFqr+cpSXxu3ryJI0eOwN7eXu24l5cX0tPTcfHiRdW+6OhoKJVKdO7cWdXmxIkTKCgoULWJjIyEh4cHbG1tyx0Lkx8iIiIp0tOE5/LKzs5GbGwsYmNjAQB37txBbGwsEhMTUVBQgDfeeAMXLlxAWFgYioqKkJKSgpSUFOTn5wMAmjdvjv79+2P8+PE4d+4cTp8+jaCgIPj7+8PFxQUA8Oabb8LExARjx47F9evXsWfPHnz22WeYMWOGVrFy2IuIiIh0duHCBfTu3Vv1uSQhCQwMRHBwMH744QcAgKenp9p5R48eRa9evQAAYWFhCAoKQp8+fSCTyTB06FCEhoaq2ioUChw+fBiTJk1Chw4dULt2bSxatEirZe4Akx8iIiJpquIXm/bq1QuiKGo8/m/HStjZ2WHXrl3/2qZNmzY4efKkVrE9i8kPERGRFOlpwrMUcc4PERERGRRWfoiIiCRJ1xVb0q2PMPkhIiKSIg57aSTdtI6IiIioDKz8EBERSZEg6LjaS7qVHyY/REREUlTFS91fJNK9MyIiIqIysPJDREQkRZzwrBGTHyIiIinisJdGTH6IiIikiJUfjaSb1hERERGVgZUfIiIiKeKwl0ZMfoiIiKSIw14aSTetIyIiIioDKz9EREQSJAgCBFZ+ysTkh4iISIKY/GjGYS8iIiIyKKz8EBERSZHwv02X8yWKyQ8REZEEcdhLMw57ERERkUFh5YeIiEiCWPnRjMkPERGRBDH50YzJDxERkQQx+dGMc36IiIjIoLDyQ0REJEVc6q4Rkx8iIiIJ4rCXZhz2IiIiIoPCyg8REZEECQJ0rPzoL5aahskPERGRBAnQcdhLwtkPh72IiIjIoLDyQ0REJEGc8KwZkx8iIiIp4lJ3jTjsRURERAaFlR8iIiIp0nHYS+SwFxEREb1IdJ3zo9tKsZqNyQ8REZEEMfnRjHN+iIiIyKCw8kNERCRFXO2lEZMfIiIiCeKwl2Yc9iIiIiKDwsoPERGRBLHyoxmTHyIiIgli8qMZh72IiIjIoLDyQ0REJEGs/GjG5IeIiEiKuNRdIw57ERERkUFh5YeIiEiCOOylGSs/REREElSS/OiyaePEiRMYNGgQXFxcIAgCwsPD1Y6LoohFixbB2dkZ5ubm8Pb2xs2bN9XapKWlISAgAHK5HDY2Nhg7diyys7PV2ly9ehXdu3eHmZkZXF1dERISovV3w+SHiIhIgqo6+cnJyUHbtm2xbt26Mo+HhIQgNDQUGzduxNmzZ2FpaQkfHx/k5uaq2gQEBOD69euIjIxEREQETpw4gQkTJqiOZ2Zmol+/fnBzc8PFixexYsUKBAcHY9OmTVrFymEvIiIi0tmAAQMwYMCAMo+Joog1a9ZgwYIF8PPzAwDs2LEDjo6OCA8Ph7+/P+Li4nDo0CGcP38eHTt2BACsXbsWr776KlauXAkXFxeEhYUhPz8fX331FUxMTNCyZUvExsZi1apVaknS87DyQ0REJEWCHjY9uXPnDlJSUuDt7a3ap1Ao0LlzZ8TExAAAYmJiYGNjo0p8AMDb2xsymQxnz55VtenRowdMTExUbXx8fBAfH4/Hjx+XOx5WfoiIiCRIXxOeMzMz1fabmprC1NRUq75SUlIAAI6Ojmr7HR0dVcdSUlLg4OCgdtzY2Bh2dnZqbRo0aFCqj5Jjtra25YqHlR8iIiLSyNXVFQqFQrUtX768ukPSGSs/FeDu7o5p06Zh2rRp1R0KaSnq4BlE//yL2r7aDraY/n+jAQBb1u7FnVt/qB3v1KUNBg/7u1R76/dEHPnpNFKS/4KJSS2069QCfX27wciI/y9BNVN2Ti4+2fwTDp64ikePs9GqaV0snTYEns3dAAA/HruCHeGncS0+CY8znyBy62y0alqvmqMmXemr8pOUlAS5XK7ar23VBwCcnJwAAKmpqXB2dlbtT01Nhaenp6rNgwcP1M4rLCxEWlqa6nwnJyekpqaqtSn5XNKmPCSV/IwaNQrbt29Xfbazs0OnTp0QEhKCNm3a6O0658+fh6Wlpd76o6rl4GSPMe+9ofosk6knLR29WsN7QBfV51omf/9nkvznQ2z/Yj969X0JbwT0R2ZGNr7fGwVRFDHAr2flB09UATM/3o0bt5OxdtFbcKqtwHc/X8CwqetxPGwenOvY4EluPjq3aYjXXmmHWZ/sru5wSU8E6Jj8/G/Sj1wuV0t+KqJBgwZwcnJCVFSUKtnJzMzE2bNn8e677wIAvLy8kJ6ejosXL6JDhw4AgOjoaCiVSnTu3FnVZv78+SgoKECtWrUAAJGRkfDw8Cj3kBcgwWGv/v37Izk5GcnJyYiKioKxsTEGDhyo12vUqVMHFhYWeu2Tqo5MJoO13FK1WVqZqx03qWWsdtzM7O//y7l2OR5OLrXxSn8v2NexRYPGrvB5rTt+ORWLvNz8qr4Voud6mpePH49fwcJJr8HLszEa1KuDWWMHwL1ebWzffxoA8J/+nTBjTH/06NS0mqOlF1l2djZiY2MRGxsLoHiSc2xsLBITEyEIAqZNm4YPP/wQP/zwA65du4aRI0fCxcUFgwcPBgA0b94c/fv3x/jx43Hu3DmcPn0aQUFB8Pf3h4uLCwDgzTffhImJCcaOHYvr169jz549+OyzzzBjxgytYpVc8mNqagonJyc4OTnB09MTc+fORVJSEh4+fAiguHw3bNgw2NjYwM7ODn5+frh7967q/FGjRmHw4MFYuXIlnJ2dYW9vj0mTJqGgoEDVxt3dHWvWrFF9vnHjBrp16wYzMzO0aNECR44cUXvA0927dyEIAvbt24fevXvDwsICbdu2Vc1wp6r16K/H+HjRF1i59Evs3fkT0h+rT+aLvXgDy+avx2cfb8fPB04iP//vf/eFhUUwrqVeMK1VyxiFBUX4M0m9FEtUExQVKlFUpISpifrPrZlpLZy7eruaoqKqUNXP+blw4QLatWuHdu3aAQBmzJiBdu3aYdGiRQCA999/H5MnT8aECRPQqVMnZGdn49ChQzAzM1P1ERYWhmbNmqFPnz549dVX0a1bN7Vn+CgUChw+fBh37txBhw4dMHPmTCxatEirZe6AxIa9npWdnY2vv/4ajRs3hr29PQoKCuDj4wMvLy+cPHkSxsbG+PDDD9G/f39cvXpVtXTu6NGjcHZ2xtGjR5GQkIDhw4fD09MT48ePL3WNoqIiDB48GPXr18fZs2eRlZWFmTNnlhnP/PnzsXLlSjRp0gTz58/HiBEjkJCQAGNjSf9rqFHquTlj6Jv9UcfBFlkZOYj+OQabQ/dgypxAmJqZoE2HZrC1lcNaYYmU+3/h5wMn8dfDxwgY8xoAoEkzN5w5fglXLt5A63ZNkZWZg6P/m0OUlZlTnbdGVCYrSzN0bOWO1dsOo4mbE+rYWWP/kYu4+OtdNKhbp7rDo8pUxS827dWrF0RR1NydIGDJkiVYsmSJxjZ2dnbYtWvXv16nTZs2OHnypHbBPUNyf+tGRETAysoKQPHTJp2dnREREQGZTIZdu3ZBqVRiy5Ytqox269atsLGxwbFjx9CvXz8AgK2tLT7//HMYGRmhWbNm8PX1RVRUVJnJT2RkJG7duoVjx46pJlstW7YMffv2LdV21qxZ8PX1BQAsXrwYLVu2REJCApo1a1bmveTl5SEvL0/1+dnlhqQ9jxZ/L5F0cqmDem5OWLFkC67FxqPjy63xUpc2aset5Zb4av23ePRXOuxr26BJM3f0f60Hvv/mCL4NOwgjYyP07vcy7t7+U9LvwaEX29qFb2P68l1oN3gRjIxkaN20HgZ7t8fV+D+efzKRBEku+enduzc2bNgAAHj8+DHWr1+PAQMG4Ny5c7hy5QoSEhJgbW2tdk5ubi5u3bql+tyyZUsYGRmpPjs7O+PatWtlXi8+Ph6urq5qs8xfeumlMtv+c9J1yWz3Bw8eaEx+li9fjsWLF//b7ZKOzC3MULuOLR49TC/zuKtb8b+ntIfFyQ8AdOvdAV17tUdWZg7MzU3xOC0ThyNOwa62ooqiJtKOe73a2L9uCp48zUNWTi4cayvwzsJtcHOxr+7QqBLxxaaaSS75sbS0ROPGjVWft2zZAoVCgc2bNyM7OxsdOnRAWFhYqfPq1Pm7/Fsyg7yEIAhQKpU6x/bPfkt+qP6t33nz5qlN4srMzISrq6vOcdDf8vLykfYoHZ7y5mUeT/6zeNmltUJ9dZ8gCJAriiuMVy/dgMLGGi71HEqdT1STWJibwsLcFOmZT3Ds3A0seO+16g6JKhGTH80kl/w8SxAEyGQyPH36FO3bt8eePXvg4OCg87K9Eh4eHkhKSkJqaqrqKZPnz5/XS98VeYom/buD3x9Hs5YNYWMrR2ZmDqIOnoEgyNC2QzM8+isdVy7egEeLBrCwMENK8l/4af8xuDeqCyeXv5Pjk9Hn0aSZOwRBwPWrCTgRdR7+gQNLLZknqimOno2DKAKN6zvgzh8PsXTdD2hc3wH+vsXLhx9n5uDPlMdI/SsDAHArsTjpd7CXw8FeP78rqeoJQvGmy/lSJbnkJy8vT/UY7MePH+Pzzz9HdnY2Bg0ahJdeegkrVqyAn58flixZgnr16uHevXvYt28f3n//fdSrp/1Dvfr27YtGjRohMDAQISEhyMrKwoIFCwBIO2t+UWWkZ2PPjp/wJCcXllbmcGtYFxOnj4CllQUKCopw6/d7OHP8EgryC6CwsUbLtk3Qq19ntT5+j7uLY4fPobCoEM4udRAw1k9tLhFRTZOVnYuPNh5A8sN02Mgt4duzLea+44taxsXD+4dP/oppH/09yXTiB8XPS5s5pj9mjS37RZVELzLJJT+HDh1SzaextrZGs2bN8M0336BXr14AgBMnTmDOnDkYMmQIsrKyULduXfTp06fClSAjIyOEh4dj3Lhx6NSpExo2bIgVK1Zg0KBBasv3qGbwD/TVeMzG1hrjJw9/bh9jJ/1HnyERVbrX+rTDa33aaTw+3Lczhvt21nicXkzFlR9dhr30GEwNI4j/ti6NKuT06dPo1q0bEhIS0KhRI731m5mZCYVCgWU/xsLM0vr5JxC9gMZ0cqvuEIgqTWZmJtyc7ZCRkaG36RdlXUOhUKDhlG9hZFrxtxEU5eXgdugblRprdZFc5ac67N+/H1ZWVmjSpAkSEhIwdepUdO3aVa+JDxEREekHkx89yMrKwpw5c5CYmIjatWvD29sbn376aXWHRUREBoyrvTRj8qMHI0eOxMiRI6s7DCIiIhWu9tKMa3OJiIjIoLDyQ0REJEEymQCZrOLlG1GHc2s6Jj9EREQSxGEvzTjsRURERAaFlR8iIiIJ4movzZj8EBERSRCHvTRj8kNERCRBrPxoxjk/REREZFBY+SEiIpIgVn40Y/JDREQkQZzzoxmHvYiIiMigsPJDREQkQQJ0HPaCdEs/TH6IiIgkiMNemnHYi4iIiAwKKz9EREQSxNVemjH5ISIikiAOe2nGYS8iIiIyKKz8EBERSRCHvTRj8kNERCRBHPbSjMkPERGRBLHyoxnn/BAREZFBYeWHiIhIinQc9pLwA56Z/BAREUkRh70047AXERERGRRWfoiIiCSIq700Y/JDREQkQRz20ozDXkRERGRQWPkhIiKSIA57acbkh4iISII47KUZh72IiIjIoLDyQ0REJEGs/GjG5IeIiEiCOOdHMyY/REREEsTKj2ac80NEREQGhZUfIiIiCeKwl2ZMfoiIiCSIw16acdiLiIiIDAorP0RERBIkQMdhL71FUvOw8kNERCRBMkHQedNGUVERFi5ciAYNGsDc3ByNGjXC0qVLIYqiqo0oili0aBGcnZ1hbm4Ob29v3Lx5U62ftLQ0BAQEQC6Xw8bGBmPHjkV2drZevpMSTH6IiIhIZ5988gk2bNiAzz//HHFxcfjkk08QEhKCtWvXqtqEhIQgNDQUGzduxNmzZ2FpaQkfHx/k5uaq2gQEBOD69euIjIxEREQETpw4gQkTJug1Vg57ERERSVBVr/Y6c+YM/Pz84OvrCwBwd3fHf//7X5w7dw5AcdVnzZo1WLBgAfz8/AAAO3bsgKOjI8LDw+Hv74+4uDgcOnQI58+fR8eOHQEAa9euxauvvoqVK1fCxcWl4jf0D6z8EBERSVDJai9dNm106dIFUVFR+P333wEAV65cwalTpzBgwAAAwJ07d5CSkgJvb2/VOQqFAp07d0ZMTAwAICYmBjY2NqrEBwC8vb0hk8lw9uxZXb8SFVZ+iIiIJEgmFG+6nA8AmZmZavtNTU1hampaqv3cuXORmZmJZs2awcjICEVFRVi2bBkCAgIAACkpKQAAR0dHtfMcHR1Vx1JSUuDg4KB23NjYGHZ2dqo2+sDKDxEREWnk6uoKhUKh2pYvX15mu7179yIsLAy7du3CpUuXsH37dqxcuRLbt2+v4oifj5UfIiIiKRJ0fFDh/05NSkqCXC5X7S6r6gMAs2fPxty5c+Hv7w8AaN26Ne7du4fly5cjMDAQTk5OAIDU1FQ4OzurzktNTYWnpycAwMnJCQ8ePFDrt7CwEGlpaarz9YGVHyIiIgkqmfCsywYAcrlcbdOU/Dx58gQymXpaYWRkBKVSCQBo0KABnJycEBUVpTqemZmJs2fPwsvLCwDg5eWF9PR0XLx4UdUmOjoaSqUSnTt31tt3w8oPERER6WzQoEFYtmwZ6tevj5YtW+Ly5ctYtWoVxowZA6C4CjVt2jR8+OGHaNKkCRo0aICFCxfCxcUFgwcPBgA0b94c/fv3x/jx47Fx40YUFBQgKCgI/v7+elvpBTD5ISIikiThf//ocr421q5di4ULF+K9997DgwcP4OLignfeeQeLFi1StXn//feRk5ODCRMmID09Hd26dcOhQ4dgZmamahMWFoagoCD06dMHMpkMQ4cORWhoaIXvoyyC+M9HL1KNlpmZCYVCgWU/xsLM0rq6wyGqFGM6uVV3CESVJjMzE27OdsjIyFCbR6PvaygUCvRfE41a5lYV7qfgaTYOTXulUmOtLpzzQ0RERAaFw15EREQSVJEHFT57vlSVK/n54Ycfyt3ha6+9VuFgiIiISD+q+vUWL5JyJT8ls7CfRxAEFBUV6RIPERERUaUqV/JTskafiIiIXgwyQYBMh/KNLufWdDrN+cnNzVVbnkZEREQ1A4e9NNN6tVdRURGWLl2KunXrwsrKCrdv3wYALFy4EF9++aXeAyQiIiLtVfVb3V8kWic/y5Ytw7Zt2xASEgITExPV/latWmHLli16DY6IiIhI37ROfnbs2IFNmzYhICAARkZGqv1t27bFjRs39BocERERVYy+3u0lRVrP+fnzzz/RuHHjUvuVSiUKCgr0EhQRERHphhOeNdO68tOiRQucPHmy1P5vv/0W7dq100tQRERERJVF68rPokWLEBgYiD///BNKpRL79u1DfHw8duzYgYiIiMqIkYiIiLQk/G/T5Xyp0rry4+fnhwMHDuDIkSOwtLTEokWLEBcXhwMHDqBv376VESMRERFpiau9NKvQc366d++OyMhIfcdCREREVOkq/JDDCxcuIC4uDkDxPKAOHTroLSgiIiLSjUwo3nQ5X6q0Tn7++OMPjBgxAqdPn4aNjQ0AID09HV26dMHu3btRr149fcdIREREWuJb3TXTes7PuHHjUFBQgLi4OKSlpSEtLQ1xcXFQKpUYN25cZcRIREREpDdaV36OHz+OM2fOwMPDQ7XPw8MDa9euRffu3fUaHBEREVWchIs3OtE6+XF1dS3zYYZFRUVwcXHRS1BERESkGw57aab1sNeKFSswefJkXLhwQbXvwoULmDp1KlauXKnX4IiIiKhiSiY867JJVbkqP7a2tmoZYE5ODjp37gxj4+LTCwsLYWxsjDFjxmDw4MGVEigRERGRPpQr+VmzZk0lh0FERET6xGEvzcqV/AQGBlZ2HERERKRHfL2FZhV+yCEA5ObmIj8/X22fXC7XKSAiIiKiyqR18pOTk4M5c+Zg7969ePToUanjRUVFegmMiIiIKk4mCJDpMHSly7k1ndarvd5//31ER0djw4YNMDU1xZYtW7B48WK4uLhgx44dlREjERERaUkQdN+kSuvKz4EDB7Bjxw706tULo0ePRvfu3dG4cWO4ubkhLCwMAQEBlREnERERkV5oXflJS0tDw4YNARTP70lLSwMAdOvWDSdOnNBvdERERFQhJau9dNmkSuvkp2HDhrhz5w4AoFmzZti7dy+A4opQyYtOiYiIqHpx2EszrZOf0aNH48qVKwCAuXPnYt26dTAzM8P06dMxe/ZsvQdIREREpE9az/mZPn266s/e3t64ceMGLl68iMaNG6NNmzZ6DY6IiIgqhqu9NNPpOT8A4ObmBjc3N33EQkRERHqi69CVhHOf8iU/oaGh5e5wypQpFQ6GiIiI9IOvt9CsXMnP6tWry9WZIAhMfoiIiKhGK1fyU7K6i2qGcS834GtESLJsOwVVdwhElUYsyn9+Iz2RoQKrmp45X6p0nvNDRERENQ+HvTSTcmJHREREVAorP0RERBIkCICMq73KxOSHiIhIgmQ6Jj+6nFvTcdiLiIiIDEqFkp+TJ0/irbfegpeXF/78808AwM6dO3Hq1Cm9BkdEREQVwxebaqZ18vPdd9/Bx8cH5ubmuHz5MvLy8gAAGRkZ+Oijj/QeIBEREWmvZNhLl02qtE5+PvzwQ2zcuBGbN29GrVq1VPu7du2KS5cu6TU4IiIiIn3TesJzfHw8evToUWq/QqFAenq6PmIiIiIiHfHdXpppXflxcnJCQkJCqf2nTp1Cw4YN9RIUERER6abkre66bFKldfIzfvx4TJ06FWfPnoUgCLh//z7CwsIwa9YsvPvuu5URIxEREWlJpodNqrQe9po7dy6USiX69OmDJ0+eoEePHjA1NcWsWbMwefLkyoiRiIiISG+0Tn4EQcD8+fMxe/ZsJCQkIDs7Gy1atICVlVVlxEdEREQVwDk/mlX4Cc8mJiZo0aKFPmMhIiIiPZFBt3k7Mkg3+9F6SK9379545ZVXNG5ERERkmP7880+89dZbsLe3h7m5OVq3bo0LFy6ojouiiEWLFsHZ2Rnm5ubw9vbGzZs31fpIS0tDQEAA5HI5bGxsMHbsWGRnZ+s1Tq2TH09PT7Rt21a1tWjRAvn5+bh06RJat26t1+CIiIioYkqGvXTZtPH48WN07doVtWrVwsGDB/Hbb7/h008/ha2trapNSEgIQkNDsXHjRpw9exaWlpbw8fFBbm6uqk1AQACuX7+OyMhIRERE4MSJE5gwYYK+vhYAFRj2Wr16dZn7g4OD9Z6ZERERUcVU9YtNP/nkE7i6umLr1q2qfQ0aNFD9WRRFrFmzBgsWLICfnx8AYMeOHXB0dER4eDj8/f0RFxeHQ4cO4fz58+jYsSMAYO3atXj11VexcuVKuLi4VPyG/kFvK9neeustfPXVV/rqjoiIiGqAzMxMta3ktVbP+uGHH9CxY0f85z//gYODA9q1a4fNmzerjt+5cwcpKSnw9vZW7VMoFOjcuTNiYmIAADExMbCxsVElPgDg7e0NmUyGs2fP6u2e9Jb8xMTEwMzMTF/dERERkQ4EQbcHHZYMe7m6ukKhUKi25cuXl3m927dvY8OGDWjSpAl+/vlnvPvuu5gyZQq2b98OAEhJSQEAODo6qp3n6OioOpaSkgIHBwe148bGxrCzs1O10Qeth72GDBmi9lkURSQnJ+PChQtYuHCh3gIjIiKiitPXUvekpCTI5XLVflNT0zLbK5VKdOzYUfWS83bt2uHXX3/Fxo0bERgYWPFAKoHWyY9CoVD7LJPJ4OHhgSVLlqBfv356C4yIiIiqn1wuV0t+NHF2di71CJzmzZvju+++A1D8eiwASE1NhbOzs6pNamoqPD09VW0ePHig1kdhYSHS0tJU5+uDVslPUVERRo8ejdatW6vN3iYiIqKapaonPHft2hXx8fFq+37//Xe4ubkBKJ787OTkhKioKFWyk5mZibNnz6pej+Xl5YX09HRcvHgRHTp0AABER0dDqVSic+fOFb+ZZ2g158fIyAj9+vXj29uJiIhqOEEP/2hj+vTp+OWXX/DRRx8hISEBu3btwqZNmzBp0qTieAQB06ZNw4cffogffvgB165dw8iRI+Hi4oLBgwcDKK4U9e/fH+PHj8e5c+dw+vRpBAUFwd/fX28rvYAKDHu1atUKt2/fVlu+RkRERDVLVVd+OnXqhP3792PevHlYsmQJGjRogDVr1iAgIEDV5v3330dOTg4mTJiA9PR0dOvWDYcOHVJbMBUWFoagoCD06dMHMpkMQ4cORWhoaMVvpAyCKIqiNiccOnQI8+bNw9KlS9GhQwdYWlqqHS/PuCBVTGZmJhQKBVIfZfB7Jsmy7RRU3SEQVRqxKB951zYjI6Pyfo+X/F3xwQ+XYWZpXeF+cnOysPi1dpUaa3Upd+VnyZIlmDlzJl599VUAwGuvvQbhH9PIRVGEIAgoKirSf5RERESklaqu/LxIyp38LF68GBMnTsTRo0crMx4iIiLSA0EQ1IoUFTlfqsqd/JSMjvXs2bPSgiEiIiKqbFpNeJZyFkhERCQlHPbSTKvkp2nTps9NgNLS0nQKiIiIiHSnryc8S5FWyc/ixYtLPeGZiIiI6EWiVfLj7+9f6oVjREREVPOUvKBUl/OlqtzJD+f7EBERvTg450ezcr/eQstnIRIRERHVSOWu/CiVysqMg4iIiPRJxwnPWr7a64Wi9bu9iIiIqOaTQYBMhwxGl3NrOiY/REREEsSl7pqVe84PERERkRSw8kNERCRBXO2lGZMfIiIiCeJzfjTjsBcREREZFFZ+iIiIJIgTnjVj8kNERCRBMug47CXhpe4c9iIiIiKDwsoPERGRBHHYSzMmP0RERBIkg27DO1IeGpLyvRERERGVwsoPERGRBAmCAEGHsStdzq3pmPwQERFJkADdXswu3dSHyQ8REZEk8QnPmnHODxERERkUVn6IiIgkSrq1G90w+SEiIpIgPudHMw57ERERkUFh5YeIiEiCuNRdMyY/REREEsQnPGsm5XsjIiIiKoWVHyIiIgnisJdmTH6IiIgkiE941ozDXkRERGRQWPkhIiKSIA57acbkh4iISIK42kszJj9EREQSxMqPZlJO7IiIiIhKYeWHiIhIgrjaSzMmP0RERBLEF5tqxmEvIiIiMiis/BAREUmQDAJkOgxe6XJuTcfkh4iISII47KUZh72IiIjIoLDyQ0REJEHC//7R5XypYvJDREQkQRz20ozDXkRERGRQmPwQERFJkPC/1V4V3XQZ9vr4448hCAKmTZum2pebm4tJkybB3t4eVlZWGDp0KFJTU9XOS0xMhK+vLywsLODg4IDZs2ejsLCwwnFowuSHiIhIgkqGvXTZKuL8+fP44osv0KZNG7X906dPx4EDB/DNN9/g+PHjuH//PoYMGaI6XlRUBF9fX+Tn5+PMmTPYvn07tm3bhkWLFunyNZSJyQ8REZEEVUfyk52djYCAAGzevBm2traq/RkZGfjyyy+xatUqvPLKK+jQoQO2bt2KM2fO4JdffgEAHD58GL/99hu+/vpreHp6YsCAAVi6dCnWrVuH/Px8fX0tAJj8EBER0b/IzMxU2/Ly8jS2nTRpEnx9feHt7a22/+LFiygoKFDb36xZM9SvXx8xMTEAgJiYGLRu3RqOjo6qNj4+PsjMzMT169f1ek9MfoiIiCRI0MM/AODq6gqFQqHali9fXub1du/ejUuXLpV5PCUlBSYmJrCxsVHb7+joiJSUFFWbfyY+JcdLjukTl7oTERFJkEwo3nQ5HwCSkpIgl8tV+01NTUu1TUpKwtSpUxEZGQkzM7OKX7SKsPJDREREGsnlcrWtrOTn4sWLePDgAdq3bw9jY2MYGxvj+PHjCA0NhbGxMRwdHZGfn4/09HS181JTU+Hk5AQAcHJyKrX6q+RzSRt9YfJDREQkQfoa9iqPPn364Nq1a4iNjVVtHTt2REBAgOrPtWrVQlRUlOqc+Ph4JCYmwsvLCwDg5eWFa9eu4cGDB6o2kZGRkMvlaNGihf6+GHDYi4iISJKq8gnP1tbWaNWqldo+S0tL2Nvbq/aPHTsWM2bMgJ2dHeRyOSZPngwvLy+8/PLLAIB+/fqhRYsWePvttxESEoKUlBQsWLAAkyZNKrPapAsmP0RERFTpVq9eDZlMhqFDhyIvLw8+Pj5Yv3696riRkREiIiLw7rvvwsvLC5aWlggMDMSSJUv0HguTHyIiIgkSoNvLSXV9tdexY8fUPpuZmWHdunVYt26dxnPc3Nzw008/6Xjl52PyQ0REJEH6Wu0lRZzwTERERAZFMpWfu3fvokGDBrh8+TI8PT1x7Ngx9O7dG48fPy71UCWif/ry25P46ruTSEpOAwA0a+iE2WMHoG/XlgCAO388xMLP9uOX2NvILyhEH6/m+GTWf+BgL/+3bomqRJd2jTD5bW+0bVYfznUUCJi1CT8dvwoAMDaSYcG7g9C3a0u41bVHZnYujp+7gcWf/4CUvzJUfTSq74AlUwajc9uGqGVshN8S7mPZxgicunhT1aZHp6aYP3EgmjdywZPcfOyOOIulGw6gqEhZ5fdM5aPtiq2yzpeqaq38jBo1CoIgYOLEiaWOTZo0CYIgYNSoURXqu0uXLkhOToZCodAxSv3btm0bE7IaxMXBBh8E+eHojvcRvX02undsioBZmxB3Kxk5T/MwJGgdBAj4fsNkHNwyHfkFRRgx4wsolfylT9XPwtwUv/7+J2aH7Cl9zMwEbZq5YsWXB9Hr7U8w8v3NaOzmiF2fvqPWbveqiTA2ksHv3VD0HhmCX2/+id2rJ8LB3hoA0KpJXexd8y6OxPyGnm99jDH/9xX692iND4L8quQeqWKq68WmL4JqH/ZydXXF7t278fTpU9W+3Nxc7Nq1C/Xr169wvyYmJnBycoIg5X97pBcDerRGv64t0ai+Axq7OWLhe6/B0sIUF369g7NXbiMx+RHWffAWWjaui5aN62J98Nu4HJeIE+d/r+7QiXDkzG9YtjECPx67WupYZk4uhgR9jvAjl5Fw7wEu/HoX76/Yi3Yt6qOeY/FLJ+0Ulmjs5oA12yNxPeE+bic9xOLPv4eluSmaN3IBALzetz2uJ9zHii2HcOePv3DmUgKC14Zj3BvdYWWh3yXIpD+CHjapqvbkp3379nB1dcW+fftU+/bt24f69eujXbt2qn2HDh1Ct27dYGNjA3t7ewwcOBC3bt3S2O+xY8cgCILa0yQ3b94MV1dXWFhY4PXXX8eqVavUKjDBwcHw9PTEzp074e7uDoVCAX9/f2RlZZU7jrt370IQBOzbtw+9e/eGhYUF2rZtq3px27FjxzB69GhkZGRAEAQIgoDg4GAdvkHSp6IiJb47fAFPnuajU+sGyMsvhCAIMDX5e4TYzMQYMpmAX65o/vkjqqnkVuZQKpXIyC7+H860jBz8fjcFw31fgoWZCYyMZBg1pBsePMpEbFwiAMDExBh5eQVq/TzNK4C5mQnaNqv4/6QSVZdqT34AYMyYMdi6davq81dffYXRo0ertcnJycGMGTNw4cIFREVFQSaT4fXXXy/30MPp06cxceJETJ06FbGxsejbty+WLVtWqt2tW7cQHh6OiIgIRERE4Pjx4/j444+1jmP+/PmYNWsWYmNj0bRpU4wYMQKFhYXo0qUL1qxZA7lcjuTkZCQnJ2PWrFllxpyXl1fqbbpUOa4n/Il6PWbAses0zFi+BztXjEezhs7o1NodFmYmCF77PZ7k5iPnaR4WfrYfRUVKpPzFfx/0YjE1MUZwkB++O3wRWTm5qv2vT/ocbZq6Iun4SqScWo333nwFb0xZj4ys4gQpOiYOL7VpiKH9OkAmE+BcR4H3xw4AADjV5ty3mkoGATJBh03CtZ8aMeH5rbfewrx583Dv3j0AxYnK7t271Z4RMHToULVzvvrqK9SpUwe//fZbqadKlmXt2rUYMGCAKtFo2rQpzpw5g4iICLV2SqUS27Ztg7V18Vj322+/jaioKFWiVN44Zs2aBV9fXwDA4sWL0bJlSyQkJKBZs2ZQKBQQBOG57ypZvnw5Fi9e/Nx7I901cXPEibB5yMx+iu+jLuO94J2I+GIqmjV0xraPx2Lmx3vwxZ7jkMkEDO3XAW2buUIm5XWgJDnGRjJsXT4WgiBg5sfq84NWvD8Mfz3Owqvj1+BpXj5GDu6C/656B30CVyD1USaOnr2BRaHhWDXPHxsXj0ReQSFWfnkIXdo3hlIUq+mO6Hl0HbqS8m+4GlH5qVOnDnx9fbFt2zZs3boVvr6+qF27tlqbmzdvYsSIEWjYsCHkcjnc3d0BAImJieW6Rnx8PF566SW1fc9+BgB3d3dV4gMAzs7Oau8ZKW8cbdq0UesDgFo/5TFv3jxkZGSotqSkJK3Op/IzqWWMhq514Nm8Pj4I8kOrJnWxcfcxAMArLzfH5fBg3Dy8HLciP8YXSwKR/CAd7nVr/3unRDVESeLj6mSL14M+V6v69OjUFD7dWmHs/K04e/U2rsb/gVmf7EVuXgFGDOysard+VzTces9G60GL0LjvXNWKsrt//lXl90OkqxpR+QGKh76CgoIAoMynPw4aNAhubm7YvHkzXFxcoFQq0apVK+Tn5+s1jlq1aql9FgRBbUirvHH8s5+SSdfarg4yNTXV+/tMqHyUooj8/EK1ffY2VgCAE+fj8fBxNgZ0b10doRFppSTxaVS/DgZNDMXjjBy14xZmJgBK/35SiiJkZSwYKVkiP9SnI/5IScOVG/yfshqLpR+Nakzy079/f+Tn50MQBPj4+Kgde/ToEeLj47F582Z0794dAHDq1Cmt+vfw8MD58+fV9j37+Xn0EQdQvBKtqKhI6/Oociz+/Ht4d2kJVydbZD3JxbeHLuDUxZv4bu17AICwH2LQtIETatta4dzVO5i36lu8N6I3mrg7VnPkRICluQkauNZRfXZzsUerpnWRnvEEKX9lYPsn49C2mSv8p2+EkZGgWr7+OOMJCgqLcO7qHaRnPcH64JFYseUgnuYVIHBwF7i52OPw6euqfie/1QdRMXFQikoM7O2JaYF9MXreV1AqOexVU/E5P5rVmOTHyMgIcXFxqj//k62tLezt7bFp0yY4OzsjMTERc+fO1ar/yZMno0ePHli1ahUGDRqE6OhoHDx4UKul8PqIAygeWsvOzkZUVBTatm0LCwsLWFhYaN0P6cdfj7PxbvAOpP6VCbmVGVo2rovv1r6H3p2bAwBu3nuAJet+wOPMJ6jvYoeZo33w3puvVHPURMU8m7sh4oupqs8fzSiel7gr4hd8vOknvNqzeAj+5K55aucNfOcznL50E2kZOXhjynoseHcQvl8/BcbGMty4nYKAWZvw680/Ve29u7TAzDE+MKlljF9v/omAWZtw5MxvVXCHRPpXY5IfAJDLy141IJPJsHv3bkyZMgWtWrWCh4cHQkND0atXr3L33bVrV2zcuBGLFy/GggUL4OPjg+nTp+Pzzz8vdx/6iAMofgDjxIkTMXz4cDx69AgffPABl7tXo7ULA/71ePBkPwRP5sPcqGY6fekmbDsFaTz+b8dKxMYl4o0pml82CQB+763VOjaqZro+qFC6hR8Iomi4U/XHjx+PGzdu4OTJk9UdSrlkZmZCoVAg9VGGxkSR6EVXnr+siV5UYlE+8q5tRkZG5f0eL/m7Ijo2EVbWFb9GdlYmXvGsX6mxVpcaVfmpbCtXrkTfvn1haWmJgwcPYvv27Vi/fn11h0VERERVyKCSn3PnziEkJARZWVlo2LAhQkNDMW7cuOoOi4iISP+42ksjg0p+9u7dW90hEBERVQmu9tLMoJIfIiIiQ6Hrm9ml/F7wGvGEZyIiIqKqwsoPERGRBHHKj2ZMfoiIiKSI2Y9GHPYiIiIig8LKDxERkQRxtZdmTH6IiIgkiKu9NOOwFxERERkUVn6IiIgkiPOdNWPyQ0REJEXMfjTisBcREREZFFZ+iIiIJIirvTRj8kNERCRBXO2lGZMfIiIiCeKUH80454eIiIgMCis/REREUsTSj0ZMfoiIiCSIE54147AXERERGRRWfoiIiCSIq700Y/JDREQkQZzyoxmHvYiIiMigsPJDREQkRSz9aMTkh4iISIK42kszDnsRERGRQWHlh4iISIK42kszJj9EREQSxCk/mjH5ISIikiJmPxpxzg8REREZFFZ+iIiIJIirvTRj8kNERCRFOk54lnDuw2EvIiIiMixMfoiIiCRI0MOmjeXLl6NTp06wtraGg4MDBg8ejPj4eLU2ubm5mDRpEuzt7WFlZYWhQ4ciNTVVrU1iYiJ8fX1hYWEBBwcHzJ49G4WFhVpG8++Y/BAREUlRFWc/x48fx6RJk/DLL78gMjISBQUF6NevH3JyclRtpk+fjgMHDuCbb77B8ePHcf/+fQwZMkR1vKioCL6+vsjPz8eZM2ewfft2bNu2DYsWLarot1AmQRRFUa89UqXJzMyEQqFA6qMMyOXy6g6HqFLYdgqq7hCIKo1YlI+8a5uRkVF5v8dL/q64fCsF1tYVv0ZWVibaNXKqcKwPHz6Eg4MDjh8/jh49eiAjIwN16tTBrl278MYbbwAAbty4gebNmyMmJgYvv/wyDh48iIEDB+L+/ftwdHQEAGzcuBFz5szBw4cPYWJiUuH7+SdWfoiIiCRI0MM/QHEy9c8tLy+vXNfPyMgAANjZ2QEALl68iIKCAnh7e6vaNGvWDPXr10dMTAwAICYmBq1bt1YlPgDg4+ODzMxMXL9+XS/fC8Dkh4iISJJKXm+hywYArq6uUCgUqm358uXPvbZSqcS0adPQtWtXtGrVCgCQkpICExMT2NjYqLV1dHRESkqKqs0/E5+S4yXH9IVL3YmIiEijpKQktWEvU1PT554zadIk/Prrrzh16lRlhlZhrPwQERFJkL7mO8vlcrXteclPUFAQIiIicPToUdSrV0+138nJCfn5+UhPT1drn5qaCicnJ1WbZ1d/lXwuaaMPTH6IiIikqIpXe4miiKCgIOzfvx/R0dFo0KCB2vEOHTqgVq1aiIqKUu2Lj49HYmIivLy8AABeXl64du0aHjx4oGoTGRkJuVyOFi1aaBfQv+CwFxERkQRV9estJk2ahF27duH777+HtbW1ao6OQqGAubk5FAoFxo4dixkzZsDOzg5yuRyTJ0+Gl5cXXn75ZQBAv3790KJFC7z99tsICQlBSkoKFixYgEmTJpVruK28mPwQERGRzjZs2AAA6NWrl9r+rVu3YtSoUQCA1atXQyaTYejQocjLy4OPjw/Wr1+vamtkZISIiAi8++678PLygqWlJQIDA7FkyRK9xsrkh4iISIIE6PZuL21PLc9jA83MzLBu3TqsW7dOYxs3Nzf89NNPWl5dO0x+iIiIJKgir6h49nyp4oRnIiIiMiis/BAREUnQPx9UWNHzpYrJDxERkSRx4EsTDnsRERGRQWHlh4iISII47KUZkx8iIiIJ4qCXZhz2IiIiIoPCyg8REZEEcdhLMyY/REREElTV7/Z6kTD5ISIikiJO+tGIc36IiIjIoLDyQ0REJEEs/GjG5IeIiEiCOOFZMw57ERERkUFh5YeIiEiCuNpLMyY/REREUsRJPxpx2IuIiIgMCis/REREEsTCj2ZMfoiIiCSIq70047AXERERGRRWfoiIiCRJt9VeUh74YvJDREQkQRz20ozDXkRERGRQmPwQERGRQeGwFxERkQRx2EszJj9EREQSxNdbaMZhLyIiIjIorPwQERFJEIe9NGPyQ0REJEF8vYVmHPYiIiIig8LKDxERkRSx9KMRkx8iIiIJ4movzTjsRURERAaFlR8iIiIJ4movzZj8EBERSRCn/GjG5IeIiEiKmP1oxDk/REREZFBY+SEiIpIgrvbSjMkPERGRBHHCs2ZMfl4goigCALIyM6s5EqLKIxblV3cIRJWm5Oe75Pd5ZcrU8e8KXc+vyZj8vECysrIAAI0buFZzJEREpIusrCwoFIpK6dvExAROTk5oooe/K5ycnGBiYqKHqGoWQayK9JP0QqlU4v79+7C2toYg5XpkDZKZmQlXV1ckJSVBLpdXdzhEesWf76oniiKysrLg4uICmazy1hzl5uYiP1/3KqqJiQnMzMz0EFHNwsrPC0Qmk6FevXrVHYZBksvl/MuBJIs/31Wrsio+/2RmZibJpEVfuNSdiIiIDAqTHyIiIjIoTH6I/oWpqSk++OADmJqaVncoRHrHn28yVJzwTERERAaFlR8iIiIyKEx+iIiIyKAw+SEiIiKDwuSHSAvu7u5Ys2ZNdYdBVMrdu3chCAJiY2MBAMeOHYMgCEhPT6/WuIhqIiY/JAmjRo2CIAiqzd7eHv3798fVq1f1ep3z589jwoQJeu2TDFfJz+3EiRNLHZs0aRIEQcCoUaMq1HeXLl2QnJxcJQ/U09a2bdtgY2NT3WGQAWPyQ5LRv39/JCcnIzk5GVFRUTA2NsbAgQP1eo06derAwsJCr32SYXN1dcXu3bvx9OlT1b7c3Fzs2rUL9evXr3C/Je934qtwiEpj8kOSYWpqCicnJzg5OcHT0xNz585FUlISHj58CABISkrCsGHDYGNjAzs7O/j5+eHu3buq80eNGoXBgwdj5cqVcHZ2hr29PSZNmoSCggJVm2eHvW7cuIFu3brBzMwMLVq0wJEjRyAIAsLDwwH8PRSxb98+9O7dGxYWFmjbti1iYmKq4iuhF0D79u3h6uqKffv2qfbt27cP9evXR7t27VT7Dh06hG7dusHGxgb29vYYOHAgbt26pbHfsoa9Nm/eDFdXV1hYWOD111/HqlWr1CowwcHB8PT0xM6dO+Hu7g6FQgF/f3/VS5XLE8fzfuaPHTuG0aNHIyMjQ1WpDQ4O1uEbJNIekx+SpOzsbHz99ddo3Lgx7O3tUVBQAB8fH1hbW+PkyZM4ffo0rKys0L9/f7WX/x09ehS3bt3C0aNHsX37dmzbtg3btm0r8xpFRUUYPHgwLCwscPbsWWzatAnz588vs+38+fMxa9YsxMbGomnTphgxYgQKCwsr49bpBTRmzBhs3bpV9fmrr77C6NGj1drk5ORgxowZuHDhAqKioiCTyfD6669DqVSW6xqnT5/GxIkTMXXqVMTGxqJv375YtmxZqXa3bt1CeHg4IiIiEBERgePHj+Pjjz/WOg5NP/NdunTBmjVrIJfLVZXaWbNmafN1EelOJJKAwMBA0cjISLS0tBQtLS1FAKKzs7N48eJFURRFcefOnaKHh4eoVCpV5+Tl5Ynm5ubizz//rOrDzc1NLCwsVLX5z3/+Iw4fPlz12c3NTVy9erUoiqJ48OBB0djYWExOTlYdj4yMFAGI+/fvF0VRFO/cuSMCELds2aJqc/36dRGAGBcXp/fvgV4sgYGBop+fn/jgwQPR1NRUvHv3rnj37l3RzMxMfPjwoejn5ycGBgaWee7Dhw9FAOK1a9dEUfz7Z+3y5cuiKIri0aNHRQDi48ePRVEUxeHDh4u+vr5qfQQEBIgKhUL1+YMPPhAtLCzEzMxM1b7Zs2eLnTt31ngPmuL4t5/5rVu3ql2XqKqx8kOS0bt3b8TGxiI2Nhbnzp2Dj48PBgwYgHv37uHKlStISEiAtbU1rKysYGVlBTs7O+Tm5qqV7Fu2bAkjIyPVZ2dnZzx48KDM68XHx8PV1RVOTk6qfS+99FKZbdu0aaPWJwCN/ZLhqVOnDnx9fbFt2zZs3boVvr6+qF27tlqbmzdvYsSIEWjYsCHkcjnc3d0BAImJieW6Rnx8fKmfz7J+Xt3d3WFtba36/Ox/A+WNgz/zVJMZV3cARPpiaWmJxo0bqz5v2bIFCoUCmzdvRnZ2Njp06ICwsLBS59WpU0f151q1aqkdEwSh3MMK/+af/ZZMQNVHvyQdY8aMQVBQEABg3bp1pY4PGjQIbm5u2Lx5M1xcXKBUKtGqVSu1YVt9eN5/A+WNgz/zVJMx+SHJEgQBMpkMT58+Rfv27bFnzx44ODhALpfrpX8PDw8kJSUhNTUVjo6OAIqXwhNVRMn8M0EQ4OPjo3bs0aNHiI+Px+bNm9G9e3cAwKlTp7Tq38PDo9TPp7Y/r/qIAyheiVZUVKT1eUT6wmEvkoy8vDykpKQgJSUFcXFxmDx5MrKzszFo0CAEBASgdu3a8PPzw8mTJ3Hnzh0cO3YMU6ZMwR9//FGh6/Xt2xeNGjVCYGAgrl69itOnT2PBggUAwOXFpDUjIyPExcXht99+Uxt6BQBbW1vY29tj06ZNSEhIQHR0NGbMmKFV/5MnT8ZPP/2EVatW4ebNm/jiiy9w8OBBrX5W9REHUDy0lp2djaioKPz111948uSJ1n0Q6YLJD0nGoUOH4OzsDGdnZ3Tu3Bnnz5/HN998g169esHCwgInTpxA/fr1MWTIEDRv3hxjx45Fbm5uhStBRkZGCA8PR3Z2Njp16oRx48apVnuZmZnp89bIQMjl8jJ/HmUyGXbv3o2LFy+iVatWmD59OlasWKFV3127dsXGjRuxatUqtG3bFocOHcL06dO1+lnVRxxA8QMYJ06ciOHDh6NOnToICQnRug8iXQiiKIrVHQSRVJw+fRrdunVDQkICGjVqVN3hEP2r8ePH48aNGzh58mR1h0JUpTjnh0gH+/fvh5WVFZo0aYKEhARMnToVXbt2ZeJDNdLKlSvRt29fWFpa4uDBg9i+fTvWr19f3WERVTkmP0Q6yMrKwpw5c5CYmIjatWvD29sbn376aXWHRVSmc+fOISQkBFlZWWjYsCFCQ0Mxbty46g6LqMpx2IuIiIgMCic8ExERkUFh8kNEREQGhckPERERGRQmP0RERGRQmPwQkVZGjRqFwYMHqz736tUL06ZNq/I4jh07BkEQkJ6errGNIAgIDw8vd5/BwcHw9PTUKa67d+9CEATExsbq1A8RVR4mP0QSMGrUKAiCAEEQYGJigsaNG2PJkiUoLCys9Gvv27cPS5cuLVfb8iQsRESVjc/5IZKI/v37Y+vWrcjLy8NPP/2ESZMmoVatWpg3b16ptvn5+TAxMdHLde3s7PTSDxFRVWHlh0giTE1N4eTkBDc3N7z77rvw9vbGDz/8AODvoaply5bBxcUFHh4eAICkpCQMGzYMNjY2sLOzg5+fH+7evavqs6ioCDNmzICNjQ3s7e3x/vvv49lHgz077JWXl4c5c+bA1dUVpqamaNy4Mb788kvcvXsXvXv3BlD8gkxBEDBq1CgAgFKpxPLly9GgQQOYm5ujbdu2+Pbbb9Wu89NPP6Fp06YwNzdH79691eIsrzlz5qBp06awsLBAw4YNsXDhQhQUFJRq98UXX8DV1RUWFhYYNmwYMjIy1I5v2bIFzZs3h5mZGZo1a8anJBO9YJj8EEmUubk58vPzVZ+joqIQHx+PyMhIREREoKCgAD4+PrC2tsbJkydx+vRpWFlZoX///qrzPv30U2zbtg1fffUVTp06hbS0NOzfv/9frzty5Ej897//RWhoKOLi4vDFF1/AysoKrq6u+O677wAA8fHxSE5OxmeffQYAWL58OXbs2IGNGzfi+vXrmD59Ot566y0cP34cQHGSNmTIEAwaNAixsbEYN24c5s6dq/V3Ym1tjW3btuG3337DZ599hs2bN2P16tVqbRISErB3714cOHAAhw4dwuXLl/Hee++pjoeFhWHRokVYtmwZ4uLi8NFHH2HhwoXYvn271vEQUTURieiFFxgYKPr5+YmiKIpKpVKMjIwUTU1NxVmzZqmOOzo6inl5eapzdu7cKXp4eIhKpVK1Ly8vTzQ3Nxd//vlnURRF0dnZWQwJCVEdLygoEOvVq6e6liiKYs+ePcWpU6eKoiiK8fHxIgAxMjKyzDiPHj0qAhAfP36s2pebmytaWFiIZ86cUWs7duxYccSIEaIoiuK8efPEFi1aqB2fM2dOqb6eBUDcv3+/xuMrVqwQO3TooPr8wQcfiEZGRuIff/yh2nfw4EFRJpOJycnJoiiKYqNGjcRdu3ap9bN06VLRy8tLFEVRvHPnjghAvHz5ssbrElH14pwfIomIiIiAlZUVCgoKoFQq8eabbyI4OFh1vHXr1mrzfK5cuYKEhARYW1ur9ZObm4tbt24hIyMDycnJ6Ny5s+qYsbExOnbsWGroq0RsbCyMjIzQs2fPcsedkJCAJ0+eoG/fvmr78/Pz0a5dOwBAXFycWhwA4OXlVe5rlNizZw9CQ0Nx69YtZGdno7CwEHK5XK1N/fr1UbduXbXrKJVKxMfHw9raGrdu3cLYsWMxfvx4VZvCwkIoFAqt4yGi6sHkh0gievfujQ0bNsDExAQuLi4wNlb/z9vS0lLtc3Z2Njp06ICwsLBSfdWpU6dCMZibm2t9TnZ2NgDgxx9/VEs6gOJ5TPoSExODgIAALF68GD4+PlAoFNi9e7dWL6ItiXXz5s2lkjEjIyO9xUpElYvJD5FEWFpaonHjxuVu3759e+zZswcODg6lqh8lnJ2dcfbsWfTo0QNAcYXj4sWLaN++fZntW7duDaVSiePHj8Pb27vU8ZLKU1FRkWpfixYtYGpqisTERI0Vo+bNm6smb5f45Zdfnn+T/3DmzBm4ublh/vz5qn337t0r1S4xMRH379+Hi4uL6joymQweHh5wdHSEi4sLbt++jYCAAK2uT0Q1Byc8ExmogIAA1K5dG35+fjh58iTu3LmDY8eOYcqUKfjjjz8AAFOnTsXHH3+M8PBw3LhxA++9996/PqPH3d0dgYGBGDNmDMLDw1V97t27FwDg5uYGQRAQERGBhw8fIjs7G9bW1pg1axamT5+O7du349atW7h06RLWrl2rmkQ8ceJE3Lx5E7Nnz0Z8fDx27dqFbdu2aXW/TZo0QWJiInbv3o1bt24hNDS0zMnbZmZmCAwMxJUrV3Dy5ElMmTIFw4YNg5OTEwBg8eLFWL58OUJDQ/H777/j2rVr2Lp1K1atWqVVPERUfZj8EBkoCwsLnDhxAvXr18eQIUPQvHlzjB07Frm5uapK0MyZM/H2228jMDAQXl5esLa2xuuvv/6v/W7YsAFvvPEG3nvvPTRr1gzjx49HTk4OAKBu3bpYvHgx5s6dC0dHRwQFBQEAli5dioULF2L58uVo3rw5+vfvjx9//BENGjQAUDwP57vvvkN4eDjatm2LjRs34qOPPtLqfl977TVMnz4dQUFB8PT0xJkzZ7Bw4cJS7Ro3bowhQ4bg1VdfRb9+/dCmTRu1pezjxo3Dli1bsHXrVrRu3Ro9e/bEtm3bVLESUc0niJpmLhIRERFJECs/REREZFCY/BAREZFBYfJDREREBoXJDxERERkUJj9ERERkUJj8EBERkUFh8kNEREQGhckPERERGRQmP0RERGRQmPwQERGRQWHyQ0RERAaFyQ8REREZlP8HgBwJ1u2EdasAAAAASUVORK5CYII=",
      "text/plain": [
       "<Figure size 640x480 with 2 Axes>"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "\n",
    "###confusion matrix\n",
    "true_labels = holdout_data['label'].astype(int).values\n",
    "\n",
    "cm = confusion_matrix(true_labels, predicted_classes)\n",
    "\n",
    "#\n",
    "disp = ConfusionMatrixDisplay(confusion_matrix=cm, display_labels=[\"Benign\", \"Malignant\"])\n",
    "\n",
    "disp.plot(cmap=plt.cm.Blues)\n",
    "plt.title(\"Confusion Matrix\")\n",
    "plt.show()\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 29,
   "id": "02fc7934",
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.metrics import f1_score\n",
    "from sklearn.metrics import precision_score\n",
    "from sklearn.metrics import recall_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 33,
   "id": "c7b1c5c8",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.934\n",
      "0.952\n",
      "0.934\n",
      "0.971\n"
     ]
    }
   ],
   "source": [
    "acc = round(accuracy_score(true_labels, predicted_classes), 3)\n",
    "f1 = round(f1_score(true_labels, predicted_classes),3)\n",
    "precision = round(precision_score(true_labels, predicted_classes),3)\n",
    "recall = round(recall_score(true_labels, predicted_classes),3)\n",
    "\n",
    "print(acc)\n",
    "print(f1)\n",
    "print(precision)\n",
    "print(recall)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "breakhis",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
