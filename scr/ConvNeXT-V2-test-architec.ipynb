{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/ms7024/home/anaconda3/envs/breakhis/lib/python3.10/site-packages/tqdm/auto.py:21: TqdmWarning: IProgress not found. Please update jupyter and ipywidgets. See https://ipywidgets.readthedocs.io/en/stable/user_install.html\n",
      "  from .autonotebook import tqdm as notebook_tqdm\n"
     ]
    }
   ],
   "source": [
    "import timm\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.optim as optim\n",
    "from urllib.request import urlopen\n",
    "from PIL import Image\n",
    "from torchvision import transforms\n",
    "from torchvision import transforms\n",
    "from torch.utils.data import DataLoader, random_split, Dataset, random_split\n",
    "import pandas as pd\n",
    "\n",
    "\n",
    "transform = transforms.Compose([\n",
    "    transforms.Resize((224, 224)),\n",
    "    transforms.ToTensor(),  # Converts to [0, 1]\n",
    "    transforms.Normalize(mean=[0.485, 0.456, 0.406],  # ImageNet stats\n",
    "                         std=[0.229, 0.224, 0.225]),\n",
    "])"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Load data"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define custom dataset\n",
    "\n",
    "class BreakHisDataset(Dataset): # Subclass Dataset, which is required for using DataLoader\n",
    "    def __init__(self, csv_path, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.transform = transform\n",
    "\n",
    "    def __len__(self):\n",
    "        return len(self.df)\n",
    "\n",
    "    def __getitem__(self, idx):\n",
    "        img_path = self.df.loc[idx, 'filepath']\n",
    "        label = self.df.loc[idx, 'label']\n",
    "        image = Image.open(img_path).convert(\"RGB\")\n",
    "        if self.transform:\n",
    "            image = self.transform(image)\n",
    "        return image, torch.tensor(label, dtype=torch.long)\n",
    "\n",
    "dataset_train = BreakHisDataset(csv_path=\"../data/augmented_train_dataset.csv\", transform=transform) # Load the data\n",
    "dataset_test = BreakHisDataset(csv_path=\"../data/new_test.csv\", transform=transform)\n",
    "\n",
    "# Create iterable data loaders\n",
    "\n",
    "train_loader = DataLoader(dataset_train, batch_size=16, shuffle=True)\n",
    "test_loader = DataLoader(dataset_test, batch_size=16, shuffle=False) # shuffle=False for consistent evaluation"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Load the pre-trained model\n",
    "\n",
    "model = timm.create_model('convnextv2_atto.fcmae', pretrained=True, num_classes=2)\n",
    "\n",
    "# Freeze all layers (can then unfreeze sequentially)\n",
    "for param in model.parameters():\n",
    "    param.requires_grad = False\n",
    "\n",
    "# Unfreeze classifier\n",
    "for param in model.head.parameters():\n",
    "    param.requires_grad = True\n",
    "    \n",
    "criterion = nn.CrossEntropyLoss()\n",
    "optimiser = optim.Adam(model.head.parameters(), lr=1e-3)\n",
    "\n",
    "train_accuracies = []\n",
    "val_accuracies = []\n",
    "train_losses = []\n",
    "val_losses = []"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Epoch [1/10], Train loss: 0.4682010176460358, Test loss: 0.4780031360248738 Train accuracy: 0.7957044673539518, Test accuracy: 0.7747808496291302\n",
      "Epoch [2/10], Train loss: 0.4018905411368793, Test loss: 0.44008527835799643 Train accuracy: 0.8281786941580757, Test accuracy: 0.8024275118004046\n",
      "Epoch [3/10], Train loss: 0.3753789940138453, Test loss: 0.4038785001512966 Train accuracy: 0.8429553264604811, Test accuracy: 0.8341200269723533\n",
      "Epoch [4/10], Train loss: 0.3579722831544188, Test loss: 0.3990984436071811 Train accuracy: 0.8546391752577319, Test accuracy: 0.8361429534726905\n",
      "Epoch [5/10], Train loss: 0.3445373062415631, Test loss: 0.39741796882105934 Train accuracy: 0.8604810996563574, Test accuracy: 0.839514497639919\n",
      "Epoch [6/10], Train loss: 0.33236337740396715, Test loss: 0.3779990894924686 Train accuracy: 0.868213058419244, Test accuracy: 0.8442346594740391\n",
      "Epoch [7/10], Train loss: 0.3239141200313863, Test loss: 0.3727940778955767 Train accuracy: 0.8719931271477663, Test accuracy: 0.8415374241402562\n",
      "Epoch [8/10], Train loss: 0.31995593696525415, Test loss: 0.3758413071215997 Train accuracy: 0.8697594501718213, Test accuracy: 0.8408631153068106\n",
      "Epoch [9/10], Train loss: 0.3119715869324314, Test loss: 0.36452849429359485 Train accuracy: 0.8752577319587629, Test accuracy: 0.8469318948078219\n",
      "Epoch [10/10], Train loss: 0.3069050353007628, Test loss: 0.3609143492344337 Train accuracy: 0.8821305841924398, Test accuracy: 0.8523263654753878\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 10\n",
    "\n",
    "for epoch in range(n_epochs):\n",
    "    model.train()\n",
    "    \n",
    "    running_loss = 0.0\n",
    "    correct = 0\n",
    "    total = 0\n",
    "    \n",
    "    for images, labels in train_loader:\n",
    "        optimiser.zero_grad()\n",
    "        outputs = model(images)\n",
    "        loss = criterion(outputs, labels)\n",
    "        loss.backward()\n",
    "        optimiser.step()\n",
    "        \n",
    "        running_loss += loss.item() * images.size(0) # Accumulate loss\n",
    "        \n",
    "        _, preds = torch.max(outputs, 1) # Take the maximum one as the class with the highest predicted probability => predicted class\n",
    "        correct += (preds == labels).sum().item() # Number of correct predictions \n",
    "        total += labels.size(0) # adding correct predictions\n",
    "        \n",
    "    # Update training losses / accuracies\n",
    "    \n",
    "    epoch_train_loss = running_loss / total\n",
    "    train_losses.append(epoch_train_loss)\n",
    "    \n",
    "    epoch_train_acc = correct / total\n",
    "    train_accuracies.append(epoch_train_acc)\n",
    "    \n",
    "    # Evaluation phase\n",
    "    \n",
    "    model.eval()\n",
    "    correct_val = 0\n",
    "    total_val = 0\n",
    "    running_val_loss = 0.0\n",
    "    \n",
    "    with torch.no_grad():\n",
    "        for images, labels in test_loader:\n",
    "            outputs = model(images)\n",
    "            loss = criterion(outputs, labels)\n",
    "            running_val_loss += loss.item() * images.size(0)\n",
    "            _, preds = torch.max(outputs, 1)\n",
    "            correct_val += (preds == labels).sum().item()\n",
    "            total_val += labels.size(0)\n",
    "    \n",
    "    epoch_val_acc = correct_val / total_val\n",
    "    epoch_val_loss = running_val_loss / total_val\n",
    "    val_accuracies.append(epoch_val_acc)\n",
    "    val_losses.append(epoch_val_loss)\n",
    "    \n",
    "    print(f\"Epoch [{epoch+1}/{n_epochs}], Train loss: {epoch_train_loss}, Test loss: {epoch_val_loss} Train accuracy: {epoch_train_acc}, Test accuracy: {epoch_val_acc}\")\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      " 0. Stages to unfreeze: 0\n",
      "Epoch 1/20: Train Accuracy 0.7951890034364261, Test Accuracy 0.7875927174645988\n"
     ]
    }
   ],
   "source": [
    "n_epochs = 20\n",
    "\n",
    "models = ['Head only', 'Stage 4', 'Stages 3-4', 'Stages 2-4', 'Stages 1-4']\n",
    "perf_train = pd.DataFrame(index=range(n_epochs), columns=models)\n",
    "perf_test = pd.DataFrame(index=range(n_epochs), columns=models)\n",
    "\n",
    "# Initialise loss criterion & optimiser\n",
    "criterion = nn.CrossEntropyLoss()\n",
    "\n",
    "# Sequentially unfreeze stages from top down\n",
    "\n",
    "n_stages = 4\n",
    "\n",
    "for i in range(n_stages+1):\n",
    "    \n",
    "    # Initialise model\n",
    "    \n",
    "    model = timm.create_model('convnextv2_atto.fcmae', pretrained=True, num_classes=2)\n",
    "    optimiser = optim.Adam(\n",
    "        [p for p in model.parameters() if p.requires_grad], \n",
    "        lr=1e-3)\n",
    "    \n",
    "    for param in model.parameters():\n",
    "        param.requires_grad = False\n",
    "        \n",
    "    for param in model.head.parameters():\n",
    "        param.requires_grad = True\n",
    "    \n",
    "    n_stages_to_unfreeze = i\n",
    "    print(f' {i}. Stages to unfreeze: {i}')\n",
    "    \n",
    "    # Unfreeze stages\n",
    "    for a in range(n_stages - n_stages_to_unfreeze, n_stages):\n",
    "        for param in model.stages[a].parameters():\n",
    "            param.requires_grad = True\n",
    "    \n",
    "    # Initialise tracking \n",
    "    \n",
    "    train_accuracies = []\n",
    "    test_accuracies = []\n",
    "    train_losses = []\n",
    "    test_losses = []\n",
    "    \n",
    "    for epoch in range(n_epochs):\n",
    "        \n",
    "        model.train()\n",
    "        \n",
    "        running_loss = 0\n",
    "        correct = 0\n",
    "        total = 0\n",
    "        \n",
    "        for images, labels in train_loader:\n",
    "            optimiser.zero_grad()\n",
    "            pred = model(images) # forward pass\n",
    "            loss = criterion(pred, labels) \n",
    "            loss.backward() # updates model.grad with partial derivatives calc via chain rule\n",
    "            optimiser.step() # take a step in negative direction of grad using calculated derivatives\n",
    "            \n",
    "            running_loss += loss.item() * images.size(0) # Accumulate loss per batch\n",
    "            \n",
    "            _, preds = torch.max(pred, 1) # Take the maximum one as the class with the highest predicted probability => predicted class\n",
    "            \n",
    "            correct += (preds == labels).sum().item()\n",
    "            total += labels.size(0)\n",
    "        \n",
    "        epoch_train_loss = running_loss/total\n",
    "        train_losses.append(epoch_train_loss)\n",
    "        \n",
    "        epoch_train_accuracy = correct/total \n",
    "        train_accuracies.append(epoch_train_accuracy)\n",
    "        \n",
    "        model.eval()\n",
    "        \n",
    "        running_loss_test = 0\n",
    "        correct_test = 0\n",
    "        total_test = 0\n",
    "        \n",
    "        with torch.no_grad():\n",
    "            for images, labels in test_loader:\n",
    "                pred = model(images)\n",
    "                loss = criterion(pred, labels)\n",
    "                running_loss_test += loss.item() * images.size(0)\n",
    "                _, preds = torch.max(pred,1)\n",
    "                \n",
    "                correct_test += (preds == labels).sum().item()\n",
    "                total_test += labels.size(0)\n",
    "            \n",
    "            \n",
    "        test_losses.append(running_loss_test/total_test)\n",
    "            \n",
    "        epoch_test_accuracy = correct_test/total_test\n",
    "        test_accuracies.append(epoch_test_accuracy)\n",
    "        \n",
    "        print(f\"Epoch {epoch+1}/{n_epochs}: Train Accuracy {epoch_train_accuracy}, Test Accuracy {epoch_test_accuracy}\")\n",
    "    \n",
    "    perf_train.iloc[:,i] = train_accuracies\n",
    "    perf_test.iloc[:,i] = test_accuracies\n",
    "\n",
    "perf_train.to_csv('convnext_v2_outputs/arc_perf_train.csv')\n",
    "perf_test.to_csv('convnext_v2_outputs/arc_perf_test.csv')\n",
    "print(perf_train)\n",
    "print(perf_test)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "BreakHis",
   "language": "python",
   "name": "breakhis"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.10.16"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
