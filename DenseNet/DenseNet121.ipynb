{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 21:55:36.656898: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import glob\n",
    "from IPython.display import Image as IPImage\n",
    "import pandas as pd             # Pandas\n",
    "import numpy as np              # NumPy\n",
    "import matplotlib.pyplot as plt # Matplotlib\n",
    "import seaborn as sns           # Seaborn\n",
    "from PIL import Image           # Pillow\n",
    "\n",
    "# Keras\n",
    "from keras.layers import Flatten, Dense, Activation, Dropout\n",
    "from keras import models, optimizers\n",
    "from keras.models import Sequential\n",
    "from keras.constraints import MaxNorm\n",
    "from keras.callbacks import ModelCheckpoint\n",
    "from keras.optimizers import Adam, Adamax\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "from keras.models import model_from_json\n",
    "from keras.regularizers import l2\n",
    "from keras.layers import Conv2D, MaxPooling2D\n",
    "from keras.applications.vgg16 import VGG16, preprocess_input\n",
    "from keras.applications import DenseNet121\n",
    "from keras.applications.densenet import DenseNet121, preprocess_input\n",
    "\n",
    "# scikit-learn\n",
    "from sklearn.model_selection import train_test_split\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import pandas as pd\n",
    "import numpy as np\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.utils import Sequence\n",
    "from PIL import Image\n",
    "\n",
    "class BreakHisKerasGenerator(Sequence):\n",
    "    def __init__(self, csv_path, batch_size=16, shuffle=True, transform=None):\n",
    "        self.df = pd.read_csv(csv_path)\n",
    "        self.batch_size = batch_size\n",
    "        self.shuffle = shuffle\n",
    "        self.transform = transform\n",
    "        self.indexes = np.arange(len(self.df))\n",
    "        self.on_epoch_end()\n",
    "\n",
    "    def __len__(self):\n",
    "        return int(np.ceil(len(self.df) / self.batch_size))\n",
    "\n",
    "    def __getitem__(self, index):\n",
    "        batch_indexes = self.indexes[index * self.batch_size:(index + 1) * self.batch_size]\n",
    "        batch_df = self.df.iloc[batch_indexes]\n",
    "        X, y = self.__data_generation(batch_df)\n",
    "        return X, y\n",
    "\n",
    "    def on_epoch_end(self):\n",
    "        if self.shuffle:\n",
    "            np.random.shuffle(self.indexes)\n",
    "\n",
    "    def __data_generation(self, batch_df):\n",
    "        X = []\n",
    "        y = []\n",
    "        for _, row in batch_df.iterrows():\n",
    "            img = Image.open(row['filepath']).convert(\"RGB\")\n",
    "            if self.transform:\n",
    "                img = self.transform(img)\n",
    "            else:\n",
    "                img = img.resize((150, 150))  # Default resizing\n",
    "            img_array = np.array(img) / 255.0\n",
    "            X.append(img_array)\n",
    "            y.append(row['label'])\n",
    "\n",
    "        X = np.array(X, dtype=np.float32)\n",
    "        y = np.array(y, dtype=np.int32)\n",
    "        return X, y"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "train_generator = BreakHisKerasGenerator(\n",
    "    csv_path=\"../data/augmented_train_dataset.csv\", batch_size=16, shuffle=True\n",
    ")\n",
    "\n",
    "valid_generator = BreakHisKerasGenerator(\n",
    "    csv_path=\"../data/new_test.csv\", batch_size=16, shuffle=False\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\">Model: \"sequential\"</span>\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1mModel: \"sequential\"\u001b[0m\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\">┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃<span style=\"font-weight: bold\"> Layer (type)                    </span>┃<span style=\"font-weight: bold\"> Output Shape           </span>┃<span style=\"font-weight: bold\">       Param # </span>┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ densenet121 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Functional</span>)        │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">4</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)     │     <span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Flatten</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">16384</span>)          │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                   │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │    <span style=\"color: #00af00; text-decoration-color: #00af00\">16,778,240</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)               │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │     <span style=\"color: #00af00; text-decoration-color: #00af00\">1,049,600</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dropout</span>)             │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">1024</span>)           │             <span style=\"color: #00af00; text-decoration-color: #00af00\">0</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">512</span>)            │       <span style=\"color: #00af00; text-decoration-color: #00af00\">524,800</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">128</span>)            │        <span style=\"color: #00af00; text-decoration-color: #00af00\">65,664</span> │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (<span style=\"color: #0087ff; text-decoration-color: #0087ff\">Dense</span>)                 │ (<span style=\"color: #00d7ff; text-decoration-color: #00d7ff\">None</span>, <span style=\"color: #00af00; text-decoration-color: #00af00\">2</span>)              │           <span style=\"color: #00af00; text-decoration-color: #00af00\">258</span> │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n",
       "</pre>\n"
      ],
      "text/plain": [
       "┏━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━━━━━━━━━━┳━━━━━━━━━━━━━━━┓\n",
       "┃\u001b[1m \u001b[0m\u001b[1mLayer (type)                   \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1mOutput Shape          \u001b[0m\u001b[1m \u001b[0m┃\u001b[1m \u001b[0m\u001b[1m      Param #\u001b[0m\u001b[1m \u001b[0m┃\n",
       "┡━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━━━━━━━━━━╇━━━━━━━━━━━━━━━┩\n",
       "│ densenet121 (\u001b[38;5;33mFunctional\u001b[0m)        │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m4\u001b[0m, \u001b[38;5;34m1024\u001b[0m)     │     \u001b[38;5;34m7,037,504\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ flatten (\u001b[38;5;33mFlatten\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m16384\u001b[0m)          │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense (\u001b[38;5;33mDense\u001b[0m)                   │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │    \u001b[38;5;34m16,778,240\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout (\u001b[38;5;33mDropout\u001b[0m)               │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_1 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │     \u001b[38;5;34m1,049,600\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dropout_1 (\u001b[38;5;33mDropout\u001b[0m)             │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m1024\u001b[0m)           │             \u001b[38;5;34m0\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_2 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m512\u001b[0m)            │       \u001b[38;5;34m524,800\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_3 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m128\u001b[0m)            │        \u001b[38;5;34m65,664\u001b[0m │\n",
       "├─────────────────────────────────┼────────────────────────┼───────────────┤\n",
       "│ dense_4 (\u001b[38;5;33mDense\u001b[0m)                 │ (\u001b[38;5;45mNone\u001b[0m, \u001b[38;5;34m2\u001b[0m)              │           \u001b[38;5;34m258\u001b[0m │\n",
       "└─────────────────────────────────┴────────────────────────┴───────────────┘\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Total params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">25,456,066</span> (97.11 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Total params: \u001b[0m\u001b[38;5;34m25,456,066\u001b[0m (97.11 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">18,418,562</span> (70.26 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Trainable params: \u001b[0m\u001b[38;5;34m18,418,562\u001b[0m (70.26 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "data": {
      "text/html": [
       "<pre style=\"white-space:pre;overflow-x:auto;line-height:normal;font-family:Menlo,'DejaVu Sans Mono',consolas,'Courier New',monospace\"><span style=\"font-weight: bold\"> Non-trainable params: </span><span style=\"color: #00af00; text-decoration-color: #00af00\">7,037,504</span> (26.85 MB)\n",
       "</pre>\n"
      ],
      "text/plain": [
       "\u001b[1m Non-trainable params: \u001b[0m\u001b[38;5;34m7,037,504\u001b[0m (26.85 MB)\n"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    }
   ],
   "source": [
    "# Load DenseNet-121 with pre-trained weights\n",
    "base_model = DenseNet121(\n",
    "    # TODO download this\n",
    "    # weights='/kaggle/input/densenet121-weights/densenet121_weights_tf_dim_ordering_tf_kernels_notop.h5',\n",
    "    weights='imagenet',\n",
    "    include_top=False, \n",
    "    input_shape=(150, 150, 3)\n",
    ")\n",
    "\n",
    "# Freeze the layers of the pre-trained model\n",
    "for layer in base_model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "# Create model\n",
    "model = Sequential()\n",
    "\n",
    "# Add the pre-trained DenseNet-121 base model\n",
    "model.add(base_model)\n",
    "\n",
    "# Flatten the output of the base model\n",
    "model.add(Flatten())\n",
    "\n",
    "# Add fully connected layers with dropout for regularization\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.5))\n",
    "model.add(Dense(1024, activation='relu'))\n",
    "model.add(Dropout(0.3))\n",
    "model.add(Dense(512, activation='relu'))\n",
    "\n",
    "# Additional layers for classification\n",
    "model.add(Dense(128, activation='relu'))\n",
    "model.add(Dense(2, activation='softmax'))\n",
    "\n",
    "# Display the summary of the model architecture\n",
    "model.summary()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "ename": "NameError",
     "evalue": "name 'plot_model' is not defined",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mNameError\u001b[0m                                 Traceback (most recent call last)",
      "Cell \u001b[0;32mIn[5], line 5\u001b[0m\n\u001b[1;32m      2\u001b[0m model_visualization_path \u001b[38;5;241m=\u001b[39m \u001b[38;5;124m\"\u001b[39m\u001b[38;5;124mdensenet/nn_architecture.png\u001b[39m\u001b[38;5;124m\"\u001b[39m\n\u001b[1;32m      4\u001b[0m \u001b[38;5;66;03m# Plot the model and save the visualization image\u001b[39;00m\n\u001b[0;32m----> 5\u001b[0m \u001b[43mplot_model\u001b[49m(model, to_file\u001b[38;5;241m=\u001b[39mmodel_visualization_path, show_shapes\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m, show_layer_names\u001b[38;5;241m=\u001b[39m\u001b[38;5;28;01mTrue\u001b[39;00m)\n\u001b[1;32m      7\u001b[0m \u001b[38;5;66;03m# Display the visualization image\u001b[39;00m\n\u001b[1;32m      8\u001b[0m IPImage(filename\u001b[38;5;241m=\u001b[39mmodel_visualization_path)\n",
      "\u001b[0;31mNameError\u001b[0m: name 'plot_model' is not defined"
     ]
    }
   ],
   "source": [
    "# Specify the file path for saving the visualization image\n",
    "model_visualization_path = \"densenet/nn_architecture.png\"\n",
    "\n",
    "# Plot the model and save the visualization image\n",
    "plot_model(model, to_file=model_visualization_path, show_shapes=True, show_layer_names=True)\n",
    "\n",
    "# Display the visualization image\n",
    "IPImage(filename=model_visualization_path)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Define the path to save the best model checkpoint\n",
    "checkpoint_path = \"densenet/model.h5\"\n",
    "\n",
    "# Create a ModelCheckpoint callback\n",
    "# This callback saves the model when validation accuracy improves\n",
    "checkpoint = ModelCheckpoint(\n",
    "    checkpoint_path,\n",
    "    monitor='val_accuracy',  # Monitor validation accuracy\n",
    "    save_best_only=True,     # Save only the best model\n",
    "    mode='max',              # Save based on the maximum validation accuracy\n",
    "    verbose=1                # Display progress information\n",
    ")  "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [],
   "source": [
    "# Compile the model with the Adam optimizer, categorical crossentropy loss, and accuracy metric\n",
    "model.compile(\n",
    "    optimizer='adam',\n",
    "    loss='sparse_categorical_crossentropy',  # Categorical crossentropy loss for multi-class classification\n",
    "    metrics=['accuracy']              # Monitor accuracy during training\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/js4124/home/anaconda3/envs/ml_py/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m0s\u001b[0m 10s/step - accuracy: 0.6974 - loss: 0.9937\n",
      "Epoch 1: val_accuracy improved from -inf to 0.80445, saving model to densenet/model.h5\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:absl:You are saving your model as an HDF5 file via `model.save()` or `keras.saving.save_model(model)`. This file format is considered legacy. We recommend using instead the native Keras format, e.g. `model.save('my_model.keras')` or `keras.saving.save_model(model, 'my_model.keras')`. \n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m364/364\u001b[0m \u001b[32m━━━━━━━━━━━━━━━━━━━━\u001b[0m\u001b[37m\u001b[0m \u001b[1m4127s\u001b[0m 11s/step - accuracy: 0.6975 - loss: 0.9926 - val_accuracy: 0.8045 - val_loss: 0.4536\n"
     ]
    }
   ],
   "source": [
    "# Train the model using the fit() method\n",
    "history = model.fit(\n",
    "    train_generator,                                   # Training data generator\n",
    "    # steps_per_epoch=toy_generator.samples // toy_generator.batch_size,  # Number of steps per epoch\n",
    "    epochs=1,                                         # Number of training epochs\n",
    "    validation_data=valid_generator,                   # Validation data generator\n",
    "    # validation_steps=valid_generator.samples // valid_generator.batch_size,  # Number of validation steps\n",
    "    callbacks=[checkpoint]                             # List of callbacks, including the ModelCheckpoint\n",
    ")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Total number of layers in the model: 427\n"
     ]
    }
   ],
   "source": [
    "total_layers = len(base_model.layers)\n",
    "print(f'Total number of layers in the model: {total_layers}')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0 input_layer\n",
      "1 zero_padding2d\n",
      "2 conv1_conv\n",
      "3 conv1_bn\n",
      "4 conv1_relu\n",
      "5 zero_padding2d_1\n",
      "6 pool1\n",
      "7 conv2_block1_0_bn\n",
      "8 conv2_block1_0_relu\n",
      "9 conv2_block1_1_conv\n",
      "10 conv2_block1_1_bn\n",
      "11 conv2_block1_1_relu\n",
      "12 conv2_block1_2_conv\n",
      "13 conv2_block1_concat\n",
      "14 conv2_block2_0_bn\n",
      "15 conv2_block2_0_relu\n",
      "16 conv2_block2_1_conv\n",
      "17 conv2_block2_1_bn\n",
      "18 conv2_block2_1_relu\n",
      "19 conv2_block2_2_conv\n",
      "20 conv2_block2_concat\n",
      "21 conv2_block3_0_bn\n",
      "22 conv2_block3_0_relu\n",
      "23 conv2_block3_1_conv\n",
      "24 conv2_block3_1_bn\n",
      "25 conv2_block3_1_relu\n",
      "26 conv2_block3_2_conv\n",
      "27 conv2_block3_concat\n",
      "28 conv2_block4_0_bn\n",
      "29 conv2_block4_0_relu\n",
      "30 conv2_block4_1_conv\n",
      "31 conv2_block4_1_bn\n",
      "32 conv2_block4_1_relu\n",
      "33 conv2_block4_2_conv\n",
      "34 conv2_block4_concat\n",
      "35 conv2_block5_0_bn\n",
      "36 conv2_block5_0_relu\n",
      "37 conv2_block5_1_conv\n",
      "38 conv2_block5_1_bn\n",
      "39 conv2_block5_1_relu\n",
      "40 conv2_block5_2_conv\n",
      "41 conv2_block5_concat\n",
      "42 conv2_block6_0_bn\n",
      "43 conv2_block6_0_relu\n",
      "44 conv2_block6_1_conv\n",
      "45 conv2_block6_1_bn\n",
      "46 conv2_block6_1_relu\n",
      "47 conv2_block6_2_conv\n",
      "48 conv2_block6_concat\n",
      "49 pool2_bn\n",
      "50 pool2_relu\n",
      "51 pool2_conv\n",
      "52 pool2_pool\n",
      "53 conv3_block1_0_bn\n",
      "54 conv3_block1_0_relu\n",
      "55 conv3_block1_1_conv\n",
      "56 conv3_block1_1_bn\n",
      "57 conv3_block1_1_relu\n",
      "58 conv3_block1_2_conv\n",
      "59 conv3_block1_concat\n",
      "60 conv3_block2_0_bn\n",
      "61 conv3_block2_0_relu\n",
      "62 conv3_block2_1_conv\n",
      "63 conv3_block2_1_bn\n",
      "64 conv3_block2_1_relu\n",
      "65 conv3_block2_2_conv\n",
      "66 conv3_block2_concat\n",
      "67 conv3_block3_0_bn\n",
      "68 conv3_block3_0_relu\n",
      "69 conv3_block3_1_conv\n",
      "70 conv3_block3_1_bn\n",
      "71 conv3_block3_1_relu\n",
      "72 conv3_block3_2_conv\n",
      "73 conv3_block3_concat\n",
      "74 conv3_block4_0_bn\n",
      "75 conv3_block4_0_relu\n",
      "76 conv3_block4_1_conv\n",
      "77 conv3_block4_1_bn\n",
      "78 conv3_block4_1_relu\n",
      "79 conv3_block4_2_conv\n",
      "80 conv3_block4_concat\n",
      "81 conv3_block5_0_bn\n",
      "82 conv3_block5_0_relu\n",
      "83 conv3_block5_1_conv\n",
      "84 conv3_block5_1_bn\n",
      "85 conv3_block5_1_relu\n",
      "86 conv3_block5_2_conv\n",
      "87 conv3_block5_concat\n",
      "88 conv3_block6_0_bn\n",
      "89 conv3_block6_0_relu\n",
      "90 conv3_block6_1_conv\n",
      "91 conv3_block6_1_bn\n",
      "92 conv3_block6_1_relu\n",
      "93 conv3_block6_2_conv\n",
      "94 conv3_block6_concat\n",
      "95 conv3_block7_0_bn\n",
      "96 conv3_block7_0_relu\n",
      "97 conv3_block7_1_conv\n",
      "98 conv3_block7_1_bn\n",
      "99 conv3_block7_1_relu\n",
      "100 conv3_block7_2_conv\n",
      "101 conv3_block7_concat\n",
      "102 conv3_block8_0_bn\n",
      "103 conv3_block8_0_relu\n",
      "104 conv3_block8_1_conv\n",
      "105 conv3_block8_1_bn\n",
      "106 conv3_block8_1_relu\n",
      "107 conv3_block8_2_conv\n",
      "108 conv3_block8_concat\n",
      "109 conv3_block9_0_bn\n",
      "110 conv3_block9_0_relu\n",
      "111 conv3_block9_1_conv\n",
      "112 conv3_block9_1_bn\n",
      "113 conv3_block9_1_relu\n",
      "114 conv3_block9_2_conv\n",
      "115 conv3_block9_concat\n",
      "116 conv3_block10_0_bn\n",
      "117 conv3_block10_0_relu\n",
      "118 conv3_block10_1_conv\n",
      "119 conv3_block10_1_bn\n",
      "120 conv3_block10_1_relu\n",
      "121 conv3_block10_2_conv\n",
      "122 conv3_block10_concat\n",
      "123 conv3_block11_0_bn\n",
      "124 conv3_block11_0_relu\n",
      "125 conv3_block11_1_conv\n",
      "126 conv3_block11_1_bn\n",
      "127 conv3_block11_1_relu\n",
      "128 conv3_block11_2_conv\n",
      "129 conv3_block11_concat\n",
      "130 conv3_block12_0_bn\n",
      "131 conv3_block12_0_relu\n",
      "132 conv3_block12_1_conv\n",
      "133 conv3_block12_1_bn\n",
      "134 conv3_block12_1_relu\n",
      "135 conv3_block12_2_conv\n",
      "136 conv3_block12_concat\n",
      "137 pool3_bn\n",
      "138 pool3_relu\n",
      "139 pool3_conv\n",
      "140 pool3_pool\n",
      "141 conv4_block1_0_bn\n",
      "142 conv4_block1_0_relu\n",
      "143 conv4_block1_1_conv\n",
      "144 conv4_block1_1_bn\n",
      "145 conv4_block1_1_relu\n",
      "146 conv4_block1_2_conv\n",
      "147 conv4_block1_concat\n",
      "148 conv4_block2_0_bn\n",
      "149 conv4_block2_0_relu\n",
      "150 conv4_block2_1_conv\n",
      "151 conv4_block2_1_bn\n",
      "152 conv4_block2_1_relu\n",
      "153 conv4_block2_2_conv\n",
      "154 conv4_block2_concat\n",
      "155 conv4_block3_0_bn\n",
      "156 conv4_block3_0_relu\n",
      "157 conv4_block3_1_conv\n",
      "158 conv4_block3_1_bn\n",
      "159 conv4_block3_1_relu\n",
      "160 conv4_block3_2_conv\n",
      "161 conv4_block3_concat\n",
      "162 conv4_block4_0_bn\n",
      "163 conv4_block4_0_relu\n",
      "164 conv4_block4_1_conv\n",
      "165 conv4_block4_1_bn\n",
      "166 conv4_block4_1_relu\n",
      "167 conv4_block4_2_conv\n",
      "168 conv4_block4_concat\n",
      "169 conv4_block5_0_bn\n",
      "170 conv4_block5_0_relu\n",
      "171 conv4_block5_1_conv\n",
      "172 conv4_block5_1_bn\n",
      "173 conv4_block5_1_relu\n",
      "174 conv4_block5_2_conv\n",
      "175 conv4_block5_concat\n",
      "176 conv4_block6_0_bn\n",
      "177 conv4_block6_0_relu\n",
      "178 conv4_block6_1_conv\n",
      "179 conv4_block6_1_bn\n",
      "180 conv4_block6_1_relu\n",
      "181 conv4_block6_2_conv\n",
      "182 conv4_block6_concat\n",
      "183 conv4_block7_0_bn\n",
      "184 conv4_block7_0_relu\n",
      "185 conv4_block7_1_conv\n",
      "186 conv4_block7_1_bn\n",
      "187 conv4_block7_1_relu\n",
      "188 conv4_block7_2_conv\n",
      "189 conv4_block7_concat\n",
      "190 conv4_block8_0_bn\n",
      "191 conv4_block8_0_relu\n",
      "192 conv4_block8_1_conv\n",
      "193 conv4_block8_1_bn\n",
      "194 conv4_block8_1_relu\n",
      "195 conv4_block8_2_conv\n",
      "196 conv4_block8_concat\n",
      "197 conv4_block9_0_bn\n",
      "198 conv4_block9_0_relu\n",
      "199 conv4_block9_1_conv\n",
      "200 conv4_block9_1_bn\n",
      "201 conv4_block9_1_relu\n",
      "202 conv4_block9_2_conv\n",
      "203 conv4_block9_concat\n",
      "204 conv4_block10_0_bn\n",
      "205 conv4_block10_0_relu\n",
      "206 conv4_block10_1_conv\n",
      "207 conv4_block10_1_bn\n",
      "208 conv4_block10_1_relu\n",
      "209 conv4_block10_2_conv\n",
      "210 conv4_block10_concat\n",
      "211 conv4_block11_0_bn\n",
      "212 conv4_block11_0_relu\n",
      "213 conv4_block11_1_conv\n",
      "214 conv4_block11_1_bn\n",
      "215 conv4_block11_1_relu\n",
      "216 conv4_block11_2_conv\n",
      "217 conv4_block11_concat\n",
      "218 conv4_block12_0_bn\n",
      "219 conv4_block12_0_relu\n",
      "220 conv4_block12_1_conv\n",
      "221 conv4_block12_1_bn\n",
      "222 conv4_block12_1_relu\n",
      "223 conv4_block12_2_conv\n",
      "224 conv4_block12_concat\n",
      "225 conv4_block13_0_bn\n",
      "226 conv4_block13_0_relu\n",
      "227 conv4_block13_1_conv\n",
      "228 conv4_block13_1_bn\n",
      "229 conv4_block13_1_relu\n",
      "230 conv4_block13_2_conv\n",
      "231 conv4_block13_concat\n",
      "232 conv4_block14_0_bn\n",
      "233 conv4_block14_0_relu\n",
      "234 conv4_block14_1_conv\n",
      "235 conv4_block14_1_bn\n",
      "236 conv4_block14_1_relu\n",
      "237 conv4_block14_2_conv\n",
      "238 conv4_block14_concat\n",
      "239 conv4_block15_0_bn\n",
      "240 conv4_block15_0_relu\n",
      "241 conv4_block15_1_conv\n",
      "242 conv4_block15_1_bn\n",
      "243 conv4_block15_1_relu\n",
      "244 conv4_block15_2_conv\n",
      "245 conv4_block15_concat\n",
      "246 conv4_block16_0_bn\n",
      "247 conv4_block16_0_relu\n",
      "248 conv4_block16_1_conv\n",
      "249 conv4_block16_1_bn\n",
      "250 conv4_block16_1_relu\n",
      "251 conv4_block16_2_conv\n",
      "252 conv4_block16_concat\n",
      "253 conv4_block17_0_bn\n",
      "254 conv4_block17_0_relu\n",
      "255 conv4_block17_1_conv\n",
      "256 conv4_block17_1_bn\n",
      "257 conv4_block17_1_relu\n",
      "258 conv4_block17_2_conv\n",
      "259 conv4_block17_concat\n",
      "260 conv4_block18_0_bn\n",
      "261 conv4_block18_0_relu\n",
      "262 conv4_block18_1_conv\n",
      "263 conv4_block18_1_bn\n",
      "264 conv4_block18_1_relu\n",
      "265 conv4_block18_2_conv\n",
      "266 conv4_block18_concat\n",
      "267 conv4_block19_0_bn\n",
      "268 conv4_block19_0_relu\n",
      "269 conv4_block19_1_conv\n",
      "270 conv4_block19_1_bn\n",
      "271 conv4_block19_1_relu\n",
      "272 conv4_block19_2_conv\n",
      "273 conv4_block19_concat\n",
      "274 conv4_block20_0_bn\n",
      "275 conv4_block20_0_relu\n",
      "276 conv4_block20_1_conv\n",
      "277 conv4_block20_1_bn\n",
      "278 conv4_block20_1_relu\n",
      "279 conv4_block20_2_conv\n",
      "280 conv4_block20_concat\n",
      "281 conv4_block21_0_bn\n",
      "282 conv4_block21_0_relu\n",
      "283 conv4_block21_1_conv\n",
      "284 conv4_block21_1_bn\n",
      "285 conv4_block21_1_relu\n",
      "286 conv4_block21_2_conv\n",
      "287 conv4_block21_concat\n",
      "288 conv4_block22_0_bn\n",
      "289 conv4_block22_0_relu\n",
      "290 conv4_block22_1_conv\n",
      "291 conv4_block22_1_bn\n",
      "292 conv4_block22_1_relu\n",
      "293 conv4_block22_2_conv\n",
      "294 conv4_block22_concat\n",
      "295 conv4_block23_0_bn\n",
      "296 conv4_block23_0_relu\n",
      "297 conv4_block23_1_conv\n",
      "298 conv4_block23_1_bn\n",
      "299 conv4_block23_1_relu\n",
      "300 conv4_block23_2_conv\n",
      "301 conv4_block23_concat\n",
      "302 conv4_block24_0_bn\n",
      "303 conv4_block24_0_relu\n",
      "304 conv4_block24_1_conv\n",
      "305 conv4_block24_1_bn\n",
      "306 conv4_block24_1_relu\n",
      "307 conv4_block24_2_conv\n",
      "308 conv4_block24_concat\n",
      "309 pool4_bn\n",
      "310 pool4_relu\n",
      "311 pool4_conv\n",
      "312 pool4_pool\n",
      "313 conv5_block1_0_bn\n",
      "314 conv5_block1_0_relu\n",
      "315 conv5_block1_1_conv\n",
      "316 conv5_block1_1_bn\n",
      "317 conv5_block1_1_relu\n",
      "318 conv5_block1_2_conv\n",
      "319 conv5_block1_concat\n",
      "320 conv5_block2_0_bn\n",
      "321 conv5_block2_0_relu\n",
      "322 conv5_block2_1_conv\n",
      "323 conv5_block2_1_bn\n",
      "324 conv5_block2_1_relu\n",
      "325 conv5_block2_2_conv\n",
      "326 conv5_block2_concat\n",
      "327 conv5_block3_0_bn\n",
      "328 conv5_block3_0_relu\n",
      "329 conv5_block3_1_conv\n",
      "330 conv5_block3_1_bn\n",
      "331 conv5_block3_1_relu\n",
      "332 conv5_block3_2_conv\n",
      "333 conv5_block3_concat\n",
      "334 conv5_block4_0_bn\n",
      "335 conv5_block4_0_relu\n",
      "336 conv5_block4_1_conv\n",
      "337 conv5_block4_1_bn\n",
      "338 conv5_block4_1_relu\n",
      "339 conv5_block4_2_conv\n",
      "340 conv5_block4_concat\n",
      "341 conv5_block5_0_bn\n",
      "342 conv5_block5_0_relu\n",
      "343 conv5_block5_1_conv\n",
      "344 conv5_block5_1_bn\n",
      "345 conv5_block5_1_relu\n",
      "346 conv5_block5_2_conv\n",
      "347 conv5_block5_concat\n",
      "348 conv5_block6_0_bn\n",
      "349 conv5_block6_0_relu\n",
      "350 conv5_block6_1_conv\n",
      "351 conv5_block6_1_bn\n",
      "352 conv5_block6_1_relu\n",
      "353 conv5_block6_2_conv\n",
      "354 conv5_block6_concat\n",
      "355 conv5_block7_0_bn\n",
      "356 conv5_block7_0_relu\n",
      "357 conv5_block7_1_conv\n",
      "358 conv5_block7_1_bn\n",
      "359 conv5_block7_1_relu\n",
      "360 conv5_block7_2_conv\n",
      "361 conv5_block7_concat\n",
      "362 conv5_block8_0_bn\n",
      "363 conv5_block8_0_relu\n",
      "364 conv5_block8_1_conv\n",
      "365 conv5_block8_1_bn\n",
      "366 conv5_block8_1_relu\n",
      "367 conv5_block8_2_conv\n",
      "368 conv5_block8_concat\n",
      "369 conv5_block9_0_bn\n",
      "370 conv5_block9_0_relu\n",
      "371 conv5_block9_1_conv\n",
      "372 conv5_block9_1_bn\n",
      "373 conv5_block9_1_relu\n",
      "374 conv5_block9_2_conv\n",
      "375 conv5_block9_concat\n",
      "376 conv5_block10_0_bn\n",
      "377 conv5_block10_0_relu\n",
      "378 conv5_block10_1_conv\n",
      "379 conv5_block10_1_bn\n",
      "380 conv5_block10_1_relu\n",
      "381 conv5_block10_2_conv\n",
      "382 conv5_block10_concat\n",
      "383 conv5_block11_0_bn\n",
      "384 conv5_block11_0_relu\n",
      "385 conv5_block11_1_conv\n",
      "386 conv5_block11_1_bn\n",
      "387 conv5_block11_1_relu\n",
      "388 conv5_block11_2_conv\n",
      "389 conv5_block11_concat\n",
      "390 conv5_block12_0_bn\n",
      "391 conv5_block12_0_relu\n",
      "392 conv5_block12_1_conv\n",
      "393 conv5_block12_1_bn\n",
      "394 conv5_block12_1_relu\n",
      "395 conv5_block12_2_conv\n",
      "396 conv5_block12_concat\n",
      "397 conv5_block13_0_bn\n",
      "398 conv5_block13_0_relu\n",
      "399 conv5_block13_1_conv\n",
      "400 conv5_block13_1_bn\n",
      "401 conv5_block13_1_relu\n",
      "402 conv5_block13_2_conv\n",
      "403 conv5_block13_concat\n",
      "404 conv5_block14_0_bn\n",
      "405 conv5_block14_0_relu\n",
      "406 conv5_block14_1_conv\n",
      "407 conv5_block14_1_bn\n",
      "408 conv5_block14_1_relu\n",
      "409 conv5_block14_2_conv\n",
      "410 conv5_block14_concat\n",
      "411 conv5_block15_0_bn\n",
      "412 conv5_block15_0_relu\n",
      "413 conv5_block15_1_conv\n",
      "414 conv5_block15_1_bn\n",
      "415 conv5_block15_1_relu\n",
      "416 conv5_block15_2_conv\n",
      "417 conv5_block15_concat\n",
      "418 conv5_block16_0_bn\n",
      "419 conv5_block16_0_relu\n",
      "420 conv5_block16_1_conv\n",
      "421 conv5_block16_1_bn\n",
      "422 conv5_block16_1_relu\n",
      "423 conv5_block16_2_conv\n",
      "424 conv5_block16_concat\n",
      "425 bn\n",
      "426 relu\n"
     ]
    }
   ],
   "source": [
    "for i, layer in enumerate(base_model.layers):\n",
    "    print(i, layer.name)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Block Freezing "
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "2025-04-20 18:09:34.466835: I tensorflow/core/platform/cpu_feature_guard.cc:210] This TensorFlow binary is optimized to use available CPU instructions in performance-critical operations.\n",
      "To enable the following instructions: SSE4.1 SSE4.2 AVX AVX2 FMA, in other operations, rebuild TensorFlow with the appropriate compiler flags.\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Found 5820 validated image filenames belonging to 2 classes.\n",
      "Found 1483 validated image filenames belonging to 2 classes.\n",
      "Unfreezing block 2 → layers 87 to 186\n",
      "Unfreezing block 3 → layers 187 to 346\n",
      "Unfreezing block 4 → layers 347 to 482\n",
      "Unfreezing block 5 → layers 483 to 483\n",
      "Unfreezing block 6 → layers 484 to 486\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "/rds/general/user/js4124/home/anaconda3/envs/ml_py/lib/python3.9/site-packages/keras/src/trainers/data_adapters/py_dataset_adapter.py:121: UserWarning: Your `PyDataset` class should call `super().__init__(**kwargs)` in its constructor. `**kwargs` can include `workers`, `use_multiprocessing`, `max_queue_size`. Do not pass these arguments to `fit()`, as they will be ignored.\n",
      "  self._warn_if_super_not_called()\n"
     ]
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\u001b[1m  8/182\u001b[0m \u001b[37m━━━━━━━━━━━━━━━━━━━━\u001b[0m \u001b[1m3:12:21\u001b[0m 66s/step - accuracy: 0.5271 - loss: 0.8455"
     ]
    }
   ],
   "source": [
    "import os\n",
    "import sys\n",
    "import numpy as np\n",
    "import pandas as pd\n",
    "import matplotlib.pyplot as plt\n",
    "import tensorflow as tf\n",
    "from tensorflow.keras.applications import DenseNet121\n",
    "from tensorflow.keras.applications.densenet import preprocess_input\n",
    "from tensorflow.keras.models import Model\n",
    "from tensorflow.keras.layers import Dense, Dropout, GlobalAveragePooling2D\n",
    "from tensorflow.keras.optimizers import Adam\n",
    "from tensorflow.keras.callbacks import EarlyStopping, ModelCheckpoint\n",
    "from tensorflow.keras.preprocessing.image import ImageDataGenerator\n",
    "\n",
    "# ================================\n",
    "# 1. Parse Block Index\n",
    "# ================================\n",
    "n_epochs = 1\n",
    "# idx = int(os.environ.get('PBS_ARRAY_INDEX', 1))  # or manually set for local testing\n",
    "idx=6\n",
    "num_blocks_to_unfreeze = idx - 1  # 0 = only top classifier trainable\n",
    "\n",
    "# ================================\n",
    "# 2. Load Data\n",
    "# ================================\n",
    "os.chdir(\"/rds/general/user/js4124/home/ML_BreakHis/scr\")\n",
    "\n",
    "train_df = pd.read_csv('../data/augmented_train_dataset.csv')\n",
    "test_df = pd.read_csv('../data/new_test.csv')\n",
    "\n",
    "train_df['label'] = train_df['label'].astype(str)\n",
    "test_df['label'] = test_df['label'].astype(str)\n",
    "train_df['filepath'] = train_df['filepath'].str.replace(r\"^\\.\\./\", \"../data/\", regex=True)\n",
    "\n",
    "image_size = 224\n",
    "datagen = ImageDataGenerator(preprocessing_function=preprocess_input)\n",
    "\n",
    "train_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=train_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=32,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "test_generator = datagen.flow_from_dataframe(\n",
    "    dataframe=test_df,\n",
    "    x_col='filepath',\n",
    "    y_col='label',\n",
    "    target_size=(image_size, image_size),\n",
    "    batch_size=16,\n",
    "    class_mode='categorical'\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 3. Define Model\n",
    "# ================================\n",
    "base_model = DenseNet121(weights='imagenet', include_top=False, input_shape=(224, 224, 3))\n",
    "x = base_model.output\n",
    "x = GlobalAveragePooling2D()(x)\n",
    "x = Dense(512, activation='relu')(x)\n",
    "x = Dropout(0.5)(x)\n",
    "predictions = Dense(2, activation='softmax')(x)\n",
    "model = Model(inputs=base_model.input, outputs=predictions)\n",
    "\n",
    "# ================================\n",
    "# 4. Define Layer Ranges for 7 Blocks\n",
    "# ================================\n",
    "block_ranges = {\n",
    "    0: (0, 6),      # Conv + Pooling\n",
    "    1: (7, 86),     # Dense Block 1 + Transition 1\n",
    "    2: (87, 186),   # Dense Block 2 + Transition 2\n",
    "    3: (187, 346),  # Dense Block 3 + Transition 3\n",
    "    4: (347, 482),  # Dense Block 4\n",
    "    5: (483, 483),  # Global Average Pooling\n",
    "    6: (484, 486),  # Classifier\n",
    "}\n",
    "\n",
    "total_blocks = len(block_ranges)\n",
    "if num_blocks_to_unfreeze > total_blocks:\n",
    "    print(f\"Error: max blocks to unfreeze is {total_blocks}\")\n",
    "    sys.exit(1)\n",
    "\n",
    "# ================================\n",
    "# 5. Freeze Layers\n",
    "# ================================\n",
    "for layer in model.layers:\n",
    "    layer.trainable = False\n",
    "\n",
    "if num_blocks_to_unfreeze == 0:\n",
    "    print(\"Training classifier only. All base layers remain frozen.\")\n",
    "else:\n",
    "    # Unfreeze the last N blocks\n",
    "    blocks_to_unfreeze = list(range(total_blocks - num_blocks_to_unfreeze, total_blocks))\n",
    "    for i in blocks_to_unfreeze:\n",
    "        start, end = block_ranges[i]\n",
    "        for layer in model.layers[start:end + 1]:\n",
    "            layer.trainable = True\n",
    "        print(f\"Unfreezing block {i} → layers {start} to {end}\")\n",
    "\n",
    "# ================================\n",
    "# 6. Compile and Train\n",
    "# ================================\n",
    "model.compile(\n",
    "    optimizer=Adam(learning_rate=1e-4),\n",
    "    loss='categorical_crossentropy',\n",
    "    metrics=['accuracy']\n",
    ")\n",
    "\n",
    "callbacks = [\n",
    "    EarlyStopping(monitor='val_loss', patience=5, restore_best_weights=True),\n",
    "    ModelCheckpoint(f\"densenet121_last_{num_blocks_to_unfreeze}_blocks.h5\", save_best_only=True)\n",
    "]\n",
    "\n",
    "history = model.fit(\n",
    "    train_generator,\n",
    "    epochs=n_epochs,\n",
    "    validation_data=test_generator,\n",
    "    callbacks=callbacks\n",
    ")\n",
    "\n",
    "# ================================\n",
    "# 7. Plot Results\n",
    "# ================================\n",
    "plt.figure(figsize=(12, 4))\n",
    "\n",
    "plt.subplot(1, 2, 1)\n",
    "plt.plot(history.history['accuracy'], label='Train Acc')\n",
    "plt.plot(history.history['val_accuracy'], label='Val Acc')\n",
    "plt.title('Accuracy Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Accuracy')\n",
    "plt.legend()\n",
    "\n",
    "plt.subplot(1, 2, 2)\n",
    "plt.plot(history.history['loss'], label='Train Loss')\n",
    "plt.plot(history.history['val_loss'], label='Val Loss')\n",
    "plt.title('Loss Over Epochs')\n",
    "plt.xlabel('Epoch')\n",
    "plt.ylabel('Loss')\n",
    "plt.legend()\n",
    "\n",
    "plt.tight_layout()\n",
    "plt.savefig(f\"training_densenet121_last_{num_blocks_to_unfreeze}_blocks.pdf\")\n",
    "plt.close()\n"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "ml_py",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.9.21"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
